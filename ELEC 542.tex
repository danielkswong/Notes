\documentclass[12pt,a4paper,titlepage]{article}
% Daniel Wong, March 2023

\usepackage[fleqn]{amsmath} % To write aligned equations
\usepackage{amssymb} % To write math symbols
\usepackage{graphicx,float} % To add pictures
\usepackage{multirow} % To add multirow lines in tables
\usepackage{multicol} % To add multicolumn lines in tables
\usepackage{hyperref} % To add hyperlinks
\usepackage[normalem]{ulem} % To underline
\usepackage[backend=bibtex,citestyle=numeric,autocite=plain,sorting=none]{biblatex} % To add references
\usepackage[english]{babel} % To write accented vowels
\usepackage[toc,page]{appendix} % To add table of contents
\usepackage{physics} % To use supported physics notation
\usepackage{mathtools}  % To use \mathclap which removes white space for subscripts
\usepackage{empheq} % To use \empheq environment
\usepackage{enumitem} % Adjust spacing of examples and proof itemize lists
\usepackage{tensor} % For subscripts to the left

\usepackage{fancyhdr} % To input custom headers
\pagestyle{fancy} % Defines header for all pages other than plain-style pages
\fancyhf{}
\rhead{\nouppercase\leftmark}
\lfoot{Daniel Wong}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt} % Defining width of header line
\renewcommand{\footrulewidth}{0.4pt} % Defining width of footer line

\usepackage{tikz} % To input mathematical plots and diagrams
\usetikzlibrary{decorations.pathreplacing,decorations.pathmorphing,decorations.markings} % For curly braces, wavy lines, and arrow markings
\usetikzlibrary{tikzmark} % For adding annotations to equations
\usetikzlibrary{shapes.geometric} % For drawing regular polygons
\usetikzlibrary{shapes.misc} % For drawing crosses
\usetikzlibrary{snakes} % For drawing zigzag lines
\usetikzlibrary{arrows.meta} % For changing arrow head sizes

\tikzset{->-/.style={decoration={markings,mark=at position #1 with {\arrow{>}}},postaction={decorate}}} 
\tikzset{-<-/.style={decoration={markings,mark=at position #1 with {\arrow{<}}},postaction={decorate}}} % Defining lines with arrows in the middle
\tikzset{cross/.style={cross out,draw,minimum size=2*(#1-\pgflinewidth),inner sep=0pt,outer sep=0pt}} % Defining cross for a node

\usepackage{color} % To use different colours
\usepackage[makeroom]{cancel} % To cancel terms in equations

\newcommand\hruleMod{% Creates a disappearing line if displayed at the top or bottom of the page
	\vskip12pt
	\nointerlineskip
	{\color{lightgray}\leaders\vrule width \textwidth\vskip0.4pt}
	\nointerlineskip
	\vskip12pt
}

\newcommand{\aside}[3][]{ % Aligns the environment for examples
	\ifthenelse{\equal{#1}{}}{\hruleMod}{}
	\begin{itemize}[align=left,labelindent=0em,labelwidth=3em,labelsep*=0.5em,leftmargin=!]
		\item[\ul{#2}:]{#3}
	\end{itemize}
	\ifthenelse{\equal{#1}{}}{\hruleMod}{}
}


\newcommand{\trm}[1]{\textrm{#1}} % Shorthand for \textrm command
\newcommand{\up}{\uparrow} % Shorthand for \uparrow command
\newcommand{\dn}{\downarrow} % Shorthand for \downarrow command
\newcommand{\en}{\epsilon_{0}} % Shorthand for \epsilon_{0}
\newcommand{\ul}[1]{\underline{\smash{#1}}} % Properly underlines words

\newcommand{\angstrom}{\textup{\AA}} % Angstrom symbol
\newcommand{\Chi}{\mathcal{X}} % Inline chi symbol
\newcommand{\Tau}{\mathcal{T}} % Capital tau symbol
\newcommand{\sign}{\trm{sign}} % Sign function
\newcommand{\pd}[1]{\partial_{#1}} % Covariant 4-gradient
\newcommand{\pu}[1]{\partial^{#1}} % Contravariant 4-gradient
\newcommand{\id}{\mathbb{I}} % Identity matrix
\newcommand{\perm}{\trm{P}} % Permutation
\renewcommand{\CancelColor}{\color{red}} % Changes the cancel colour to red


\begin{document}
\title{ELEC 542: Nanoscale Modeling and Simulations}
\author{Daniel Wong\\University of British Columbia\\Instructor: Dr. Alireza Nojeh}
\date{Winter 2022}
\maketitle

\setlength\parindent{0pt}
\pagenumbering{roman}
\numberwithin{equation}{section}

\section*{Disclaimer}
These notes may be freely used by anyone who comes across them. If any errors are found within these notes, please email me at \ul{temp@temp.com}. If you are the previous instructor of this course (Dr. Alireza Nojeh) and have concerns about keeping these notes on my website, please contact me at the email provided.\\

Other course notes may be found on my website at \url{www.temp.com/notes}.

\newpage
\tableofcontents
\newpage
\pagenumbering{arabic}

\section{Introduction}
Note the challenge of simulating systems at the nanoscale: too many particles to keep track of but not enough particles to treat statistically and as a continuum.\\

In the context of this course, the equation of motion for electrons is the Schr\"{o}dinger equation and the nucleus will be considered as point particles.\\

The map of the course content is as follows:
\begin{center}
\begin{tikzpicture}
	\draw (0,0) rectangle node{Hartree-Fock} (4,2);
	\draw[red,-{Implies},shorten >=1mm,shorten <=1.5mm,double distance=5pt,line width=2 pt] (2,0) -- (2,-1);
	\draw (0,-1) rectangle node[align=center,text width=4cm]{Post Hartree-Fock} (4,-3);
	\draw (0,-4) rectangle node[align=center,text width=4cm]{Density functional theory} (4,-6);
	\draw[red,-{Implies},shorten >=1mm,shorten <=1.5mm,double distance=5pt,line width=2 pt] (0,1) -- (-1,1) -- (-1,-5) -- (0,-5);
	\draw[dashed,rounded corners] (-1.5,2.5) rectangle (4.5,-6.5);
	\draw (0,-7.5) rectangle node[align=center,text width=4cm]{Semi-empirical} (4,-9.5);
	\draw (6,-7.5) rectangle node[align=center]{Electronic} (10,-8.25);
	\draw (6,-8.75) rectangle node[align=center]{Molecular dynamics} (10,-9.5);
	\draw[dashed,rounded corners] (-1.5,-7) rectangle (10.5,-10);
	\draw[red,-{Implies},shorten >=1mm,shorten <=1.5mm,double distance=5pt,line width=2 pt] (-1,-6.5) -- (-1,-8.75) -- (0,-8.75);
	\draw[->,shorten >=1mm,shorten <=1.5mm,line width=1 pt] (4,-8.25) -- (6,-7.875);
	\draw[->,shorten >=1mm,shorten <=1.5mm,line width=1 pt] (4,-8.75) -- (6,-9.125);
	\draw[decorate,decoration={brace,amplitude=10pt}] (5,2) -- (5,-3) node[right,midway,xshift=0.5cm] {First half of the course};
	\draw[decorate,decoration={brace,amplitude=10pt}] (11,-4) -- (11,-9.5) node[right,midway,xshift=0.5cm,text width=3cm] {Second half of the course};
\end{tikzpicture}
\end{center}

Let us consider the Schr\"{o}dinger equation for a system.
\begin{equation}
	\tikzmarknode{A}{\vb{H}}\tikzmarknode{B}{\Psi}=\tikzmarknode{C}{E}\Psi \quad (\trm{time-independent})
\end{equation}
\begin{tikzpicture}[overlay,remember picture,shorten <=1mm,font=\footnotesize]
	\draw[red,->] (A.south) -- ++ (-0.3,-0.3) node[left,xshift=0.1cm,yshift=-0.1cm] {Hamiltonian};
	\draw[red,->] (B.south) -- ++ (0,-0.5) node[below] {wavefunction};
	\draw[red,->] (C.south) -- ++ (0.3,-0.3) node[right,xshift=-0.1cm,yshift=-0.1cm] {energy eigenvalue};
\end{tikzpicture}

The wavefunction is a function of all the electron and nuclei coordinates
\begin{equation}
	\Psi=\Psi\qty(\vec{r}_{1},\ldots,\vec{r}_{N},\vec{R}_{1},\ldots,\vec{R}_{M})\quad(\trm{many-body wavefunction})
\end{equation}

\begin{center}
\begin{tikzpicture}
	\draw[ultra thick,->] (0,0) -- (0,4) node[above]{$z$};
	\draw[ultra thick,->] (0,0) -- (4,0) node[right]{$y$};
	\draw[ultra thick,->] (0,0) -- (-1,-1) node[below left]{$x$};
	\draw[->] (0,0) -- (1,2) node[above]{$\vec{r}_{i}$};
	\draw[->] (0,0) -- (3,1.5) node[right]{$\vec{R}_{A}$};
	\node[right] at (5,3) {$i=1,\ldots,N$ (number of e$^{-}$)};
	\node[right] at (5,2) {$A=1,\ldots,M$ (number of nuclei)};
\end{tikzpicture}
\end{center}

The Hamiltonian of the system is as follows
\begin{equation}
\begin{aligned}
\vb{H}&=\color{red}\underbrace{\color{black}\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}}_{\trm{e$^{-}$ KE}}\quad{\color{black}+}\quad\underbrace{\color{black}\sum_{A=1}^{M}-\frac{1}{2M_{A}}\nabla_{A}^{2}}_{\trm{nuclei KE}}\quad{\color{black}+}\quad\underbrace{\color{black}\sum_{i=1}^{N}\sum_{j>i}^{N}\frac{1}{r_{ij}}}_{\trm{e$^{-}$-e$^{-}$ repulsion}}\\
&\color{red}\quad{\color{black}+}\quad\underbrace{\color{black}\sum_{A=1}^{M}\sum_{B>A}^{M}\frac{Z_{A}Z_{B}}{R_{AB}}}_{\trm{nucleus-nucleus repulsion}}\quad{\color{black}+}\quad\underbrace{\color{black}\sum_{i=1}^{N}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}}}_{\trm{e$^{-}$-nucleus repulsion}}
\end{aligned}
\end{equation}

This is the (non-relativistic) theory of everything. Note that this is written in atomic coordinates (hence the mass and charge of electrons are 1). Note that spin is also missing from the equation above.\\

In condensed matter physics, one gets accustomed to imagining quasi-particles. These quasi-particles are models of a higher-abstraction that helps give insight into the behaviour of the system. Rather than appearing to neglect this quasi-particle picture in the Hamiltonian above, the picture comes out from the Hamiltonian equation. At the start of this course, we will want to solve this Hamiltonian without jumping straight away to the usage of quasi-particles or using approximations.\\

Let us also make a note about states. Consider a carbon atom.
\begin{center}
\begin{tikzpicture}
	\draw (0,0) node[left] {1s} -- (2,0);
	\draw [red,-{Straight Barb[left]}] (0.95,-0.2) -- (0.95,0.2);
	\draw [red,-{Straight Barb[left]}] (1.05,0.2) -- (1.05,-0.2);
	\draw (0,0.5) node[left] {2s} -- (2,0.5);
	\draw [red,-{Straight Barb[left]}] (0.95,0.3) -- (0.95,0.7);
	\draw [red,-{Straight Barb[left]}] (1.05,0.7) -- (1.05,0.3);
	\draw (0,1) node[left] {2p} -- (2,1);
	\draw [red,-{Straight Barb[left]}] (0.95,0.8) -- (0.95,1.2);
	\draw [red,-{Straight Barb[left]}] (1.05,1.2) -- (1.05,0.8);
	\draw (0,1.5) -- (2,1.5);
	\draw (0,2) node[left,yshift=0.1cm,xshift=-0.1cm] {$\vdots$} -- (2,2);
	\node at (1,2.7) {$\vdots$};
	\draw[dashed,rounded corners] (-1,-0.5) rectangle (2.5,1.3);
	\draw (4,0) node[left] {1s} -- (6,0);
	\draw [red,-{Straight Barb[left]}] (4.95,-0.2) -- (4.95,0.2);
	\draw [red,-{Straight Barb[left]}] (5.05,0.2) -- (5.05,-0.2);
	\draw (4,0.5) node[left] {2s} -- (6,0.5);
	\draw [red,-{Straight Barb[left]}] (4.95,0.3) -- (4.95,0.7);
	\draw [red,-{Straight Barb[left]}] (5.05,0.7) -- (5.05,0.3);
	\draw (4,1) node[left] {2p} -- (6,1);
	\draw [red,-{Straight Barb[left]}] (4.95,0.8) -- (4.95,1.2);
	\draw [red,-{Straight Barb[left]}] (4.95,1.8) -- (4.95,2.2);
	\draw (4,1.5) -- (6,1.5);
	\draw (4,2) node[left,yshift=0.1cm,xshift=-0.1cm] {$\vdots$} -- (6,2);
	\node at (5,2.7) {$\vdots$};
	\draw[dashed,rounded corners] (3,-0.5) rectangle (6.5,2.3);
	\node at (0.75,-1) {Ground state};
	\node at (4.75,-1) {Excited state};
\end{tikzpicture}
\end{center}
Note that the entire population of electrons in this configuration is the ground state. In a one-electron picture, one may grow accustomed to thinking of the 1s orbital as the ground state, which we will want to move away from.

\newpage
\section{Hartree-Fock}
Let us try to decouple this problem into two problems: an electronic portion and a nuclei portion.

\subsection{Born-Oppenheimer Approximation}
Note that the mass of the nucleus is many orders of magnitude larger than the mass of the electron. One should expect that the nuclei moves much slower than the electrons.\\

One can make the Born-Oppenheimer approximation. At a given moment in time, we assume that the nuclei are fixed and that the electrons are moving in the background of these fixed nuclei.\\

Thus, the variables $\vec{R}_{1},\ldots,\vec{R}_{M}$ now represent fixed positions. The second term of the Hamiltonian now drops out and the fourth term just becomes a fixed constant. We now treat the many-body wavefunction as
\begin{equation}
\Psi=\Psi_{\trm{elec}}(\color{red}\underbrace{\color{black}\vec{r}_{1},\ldots,\vec{r}_{N}}_{\substack{\trm{explicit}\\\trm{variables}}},\underbrace{\color{black}\vec{R}_{1},\ldots,\vec{R}_{M}}_{\trm{parameters}}{\color{black})\Psi_{\trm{nucl}}(}\underbrace{\color{black}\vec{R}_{1},\ldots,\vec{R}_{M}}_{\substack{\trm{explicit}\\\trm{variables}}}{\color{black})}
\end{equation}
The methodology for solving the motion of the system thus starts with solving the many-body electronic problem in the background of fixed nuclei. From this solution, one can calculate the forces acting on the nuclei from the electronic cloud and other nuclei and evolve the nuclei by one time-step. One then again makes the Born-Oppenheimer approximation and recalculates the electronic solution in the new background of fixed nuclei. These steps are then iterated to find the motion of the system in a ``quasi-static" manner.\\

Note for the nuclei portion, one is not looking at the effects of fixed electrons in space acting on the nuclei. Rather one is looking at the average effects by the electron cloud on the nuclei. Thus, $\Psi_{\trm{nucl}}$ does not parametrically depend on the electron coordinates.\\

Thus, in more detail
\begin{equation}
\begin{aligned}
\vb{H}\Psi&=\qty(\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}\Psi_{\trm{elec}})\Psi_{\trm{nucl}}+\qty(\sum_{A=1}^{M}-\frac{1}{2M_{A}}\nabla_{A}^{2}\qty(\Psi_{\trm{elec}}\Psi_{\trm{nucl}}))\\
&\quad+\qty(\sum_{i=1}^{N}\sum_{j>i}^{N}\frac{1}{r_{ij}})\Psi_{\trm{elec}}\Psi_{\trm{nucl}}+\qty(\sum_{A=1}^{M}\sum_{B>A}^{M}\frac{Z_{A}Z_{B}}{R_{AB}})\Psi_{\trm{elec}}\Psi_{\trm{nucl}}\\
&\quad+\qty(\sum_{i=1}^{N}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}})\Psi_{\trm{elec}}\Psi_{\trm{nucl}}\\
&=\qty[\qty(\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}+\sum_{i=1}^{N}\sum_{j>i}^{N}\frac{1}{r_{ij}}+\sum_{i=1}^{N}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}})\Psi_{\trm{elec}}]\Psi_{\trm{nucl}}\\
&\quad+\sum_{A=1}^{M}\sum_{B>A}^{M}\frac{Z_{A}Z_{B}}{R_{AB}}\Psi_{\trm{elec}}\Psi_{\trm{nucl}}\\
&\quad+\sum_{A=1}^{M}-\frac{1}{2M_{A}}\big[\cancelto{\mathrlap{\trm{neglect}}}{\qty(\nabla_{A}^{2}\Psi_{\trm{elec}})\Psi_{\trm{nucl}}}+\qty(\nabla_{A}^{2}\Psi_{\trm{nucl}})\Psi_{\trm{elec}}+\cancelto{\mathrlap{\trm{neglect}}}{2\qty(\nabla_{A}\Psi_{\trm{elec}})\qty(\nabla_{A}\Psi_{\trm{nucl}})}]
\end{aligned}
\end{equation}

Compare the terms $\nabla_{A}\Psi_{\trm{elec}}$ to $\nabla_{A}\Psi_{\trm{nucl}}$.
\begin{center}
\begin{tikzpicture}
	\draw[domain=-2:2,samples=200] plot (\x, {2*exp(-(\x)^2/2)});
	\draw[domain=-2:2,samples=200,red,dashed] plot (\x, {2*exp(-(\x-0.2)^2/2)});
	\draw[<-] (-1.15,1.15) -- (-1.5,1.5) node[above left] {$\Psi_{\trm{elec}}$};
	\filldraw[black] (0,-0.2) circle (1pt);
	\filldraw[red] (0.2,-0.2) circle (1pt);
	\draw[|-|] (0,-0.4) -- node[below,text width=4cm,align=center] {small nucleus movement} (0.2,-0.4);
	\draw[->] (0.3,2.3) -- (0.3,2.1) node[above,yshift=0.1cm] {small change};
	\draw[->] (0.3,1.6) -- (0.3,1.8);
	\draw[domain=4.7:5.35,samples=200] plot (\x, {2*exp(-(\x-5)^2/0.01)});
	\draw[domain=4.9:5.55,samples=200,red,dashed] plot (\x, {2*exp(-(\x-5.2)^2/0.01)});
	\draw[<-] (4.75,1.15) -- (4.4,1.5) node[above left] {$\Psi_{\trm{nucl}}$};
	\draw[->] (5.1,2.3) -- (5.1,2.1) node[above,yshift=0.1cm] {large change};
	\filldraw[black] (5,-0.2) circle (1pt);
	\filldraw[red] (5.2,-0.2) circle (1pt);
	\draw[|-|] (5,-0.4) -- node[below,text width=4cm,align=center] {small nucleus movement} (5.2,-0.4);
\end{tikzpicture}
\end{center}
The electron cloud around a nucleus does not change significantly for small movements of the nucleus. In comparison, the nucleus wavefunction changes significantly with movement of the nucleus. Thus, we expect the first and third term on the third line of the equation above to be much smaller than the second term. Therefore
\begin{equation}
\begin{aligned}
	\vb{H}\Psi&\approx\bigg[\bigg(\overbrace{\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}+\sum_{i=1}^{N}\sum_{j>i}^{N}\frac{1}{r_{ij}}+\sum_{i=1}^{N}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}}}^{E_{\trm{elec}}}\bigg)\Psi_{\trm{elec}}\bigg]\Psi_{\trm{nucl}}\\
&\quad+\sum_{A=1}^{M}\sum_{B>A}^{M}\frac{Z_{A}Z_{B}}{R_{AB}}\Psi_{\trm{elec}}\Psi_{\trm{nucl}}+\sum_{A=1}^{M}-\frac{1}{2M_{A}}\qty(\nabla_{A}^{2}\Psi_{\trm{nucl}})\Psi_{\trm{elec}}\\
&=E\Psi_{\trm{elec}}\Psi_{\trm{nucl}}]]
\end{aligned}
\end{equation}
\begin{equation}
\implies\bigg[\sum_{A=1}^{M}-\frac{1}{2M_{A}}\nabla_{A}^{2}+\color{red}\underbrace{\color{black}\sum_{A=1}^{M}\sum_{B>A}^{M}\frac{Z_{A}Z_{B}}{R_{AB}}+E_{\trm{elec}}}_{\substack{\trm{potential energy landscape}\\\trm{for nuclear motion}}}\color{black}\bigg]\Psi=E\Psi
\end{equation}
To calculate the force on the nuclei, one would want to find the derivative of this nuclear energy with respect to these nuclei coordinates. This can be done easily using the Hellman-Feynman theorem. Thus, one can do dynamics of the nuclei.

\subsection{Pauli Exclusion Principle and Hartree Products}
Back to the electronic problem:

\begin{equation}
\vb{H}_{\trm{elec}}\Psi_{\trm{elec}}=E_{\trm{elec}}\Psi_{\trm{elec}}\quad(\trm{Schr\"{o}dinger equation})
\end{equation}
where
\begin{equation}
\vb{H}_{\trm{elec}}=\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}+\sum_{i=1}^{N}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}}+\sum_{i=1}^{N}\sum_{j>i}^{N}\frac{1}{r_{ij}}
\end{equation}

One half of the story is still missing: the Pauli exclusion principle. One must now talk about electron spin.\\

Consider the one-electron problem.
\begin{equation}
\Chi(\overbrace{\vec{r}_{1},\omega_{1}}^{\vec{x}_{1}})=\begin{cases}
\Psi(\vec{r}_{1})\alpha(\omega_{1})&\\
\hfil\small\trm{or}&(\trm{one-electron wavefunction})\\
\vphantom{\Psi(\vec{r}_{1})\beta(\omega_{1})}
\smash{\color{red}\underbrace{\color{black}\Psi(\vec{r}_{1})}_{\footnotesize\substack{\trm{spatial}\\\trm{orbitals}}}}\smash{\color{red}\underbrace{\color{black}\beta(\omega_{1})}_{\footnotesize\substack{\trm{spin}\\\trm{orbitals}}}}&
\end{cases}
\vphantom{\begin{cases}
\Psi(\vec{r}_{1})\alpha(\omega_{1})&\\
\hfil\small\trm{or}&(\trm{one-electron wavefunction})\\
\vphantom{\Psi(\vec{r}_{1})\beta(\omega_{1})}
\color{red}\underbrace{\Psi(\vec{r}_{1})}_{\footnotesize\substack{\trm{spatial}\\\trm{orbitals}}}\underbrace{\beta(\omega_{1})}_{\footnotesize\substack{\trm{spin}\\\trm{orbitals}}}&
\end{cases}}
\end{equation}
where
\begin{equation}
\int\alpha^{*}(\omega_{1})\beta(\omega_{1})\dd{\omega_{1}}=0
\end{equation}
and
\begin{equation}
\int\alpha^{*}(\omega_{1})\alpha(\omega_{1})\dd{\omega_{1}}=\int\beta^{*}(\omega_{1})\beta(\omega_{1})\dd{\omega_{1}}=1
\end{equation}
Generalizing, the many-electron wavefunction is
\begin{equation}
\Chi(\color{red}\underbrace{\color{black}\vec{x}_{1},\ldots,\vec{x}_{N}}_{4N\trm{ variables}}\color{black})
\end{equation}
By Pauli's principle, the wavefunction is anti-symmetric by exchange.
\begin{equation}
\Chi(\vec{x}_{1},\cdots,\vec{x}_{i},\cdots,\vec{x}_{j},\cdots,\vec{x}_{N})=-\Chi(\vec{x}_{1},\cdots,\tikzmarknode{xj}{\vec{x}_{j}},\cdots,\tikzmarknode{xi}{\vec{x}_{i}},\cdots,\vec{x}_{N})
\end{equation}
\begin{tikzpicture}[overlay,remember picture,yshift=-0.2cm]
	\draw[red,<->] (xj.south) to[bend right] node[midway, below]{swapped} (xi.south);
\end{tikzpicture}

One must find the solution of Schr\"{o}dinger's equation in the form of an anti-symmetric wavefunction. Let us try a separation of variables (which may not always be justified) for each electron. The first two terms of the electronic Hamiltonian lends itself easily to separating each electron. The third term in $\vb{H}_{\trm{elec}}$ couples the electrons together. As a first step, let us neglect this troublesome third term.
\begin{equation}
\begin{aligned}
\vb{H}_{\trm{elec}}&\approx\sum_{i=1}^{N}\bigg(\underbrace{-\frac{1}{2}\nabla_{i}^{2}+\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}}}_{\vb{h}(i)\,:\,\trm{1-e$^{-}$ Hamiltonian}}\bigg)\\
&=\vb{h}(1)+\vb{h}(2)+\ldots+\vb{h}(N)\quad\quad\trm{(Hartree approximation)}
\end{aligned}
\end{equation}
Let us now separate the wavefunction $\Chi(\vec{x}_{1},\cdots,\vec{x}_{N})$ as
\begin{equation}
\Chi(\vec{x}_{1},\cdots,\vec{x}_{N})=\Chi_{1}(\vec{x}_{1})\Chi_{2}(\vec{x}_{2})\ldots\Chi_{N}(\vec{x}_{N})\quad\trm{(Hartree product)}
\end{equation}
Thus, the Schr\"{o}dinger equation becomes
\begin{equation}
\qty(\vb{h}(1)+\ldots+\vb{h}(N))\qty(\Chi_{1}(\vec{x}_{1})\cdots\Chi_{N}(\vec{x}_{N}))=E\qty(\Chi_{1}(\vec{x}_{1})\cdots\Chi_{N}(\vec{x}_{N}))
\end{equation}
with $E=E_{1}+\ldots+E_{N}$.\\

The problem is now reduced to
\begin{empheq}[left=\empheqlbrace]{align}
\vb{h}(1)\Chi_{1}(\vec{x}_{1})&=E_{1}\Chi_{1}(\vec{x}_{1})\\
& \vdots\\
\vb{h}(N)\Chi_{N}(\vec{x}_{N})&=E_{N}\Chi_{N}(\vec{x}_{N})
\end{empheq}
Note that these are all the same equation. Thus
\begin{equation}
\vb{h}(1)\Chi_{i}(\vec{x}_{1})=E_{i}\Chi_{i}(\vec{x}_{1}),\quad i=1,\cdots,\infty
\end{equation}
Each Hartree product is a solution to the Schr\"{o}dinger equation with energy eigenvalue $E$ which is a sum of all $E_{i}$. Note that are infinitely many solutions.

\subsection{Slater Determinants}
Note that the solution of the full electron Hamiltonian is a function of $3N$ variables (where $N$ is the number of electrons). This is an incredibly difficult problem to solve numerically.\\

Consider the Hartree product.
\begin{equation}
\Chi(\vec{x}_{1},\cdot,\vec{x}_{N})=\Chi_{1}(\vec{x}_{1})\ldots\Chi_{N}(\vec{x}_{N})
\end{equation}
Note that this form of the many-electron wavefunction is not anti-symmetric under exchange. Let us introduce the Slater determinant to solve this issue. Consider a system with two electrons. The Slater determinant is
\begin{equation}
\Chi(\vec{x}_{1},\vec{x}_{2})=\frac{1}{\sqrt{2}}\qty[\Chi_{1}(\vec{x}_{1})\Chi_{2}(\vec{x}_{2})-\Chi_{1}(\vec{x}_{2})\Chi(\vec{x}_{1})]
\end{equation}
One can see that $\Chi(\vec{x}_{2},\vec{x}_{1})=-\Chi(\vec{x}_{1},\vec{x}_{2})$. Moreover, $\Chi(\vec{x}_{1},\vec{x}_{1})=\Chi(\vec{x}_{2},\vec{x}_{2})=0$, which matches the description of the Pauli exclusion principle.\\

In determinant form, the Slater determinant is
\begin{equation}
\Chi(\vec{x}_{1},\vec{x}_{2})=\frac{1}{\sqrt{2}}\mdet{\Chi_{1}(\vec{x}_{1}) & \Chi_{2}(\vec{x}_{1})\\ \Chi_{1}(\vec{x}_{2}) & \Chi_{2}(\vec{x}_{2})}
\end{equation}
Generalizing to $N$ electrons
\begin{equation}
\Chi(\vec{x}_{1},\cdots,\vec{x}_{N})={\frac{1}{\sqrt{\tikzmarknode{A}{N}!}}}\mdet{\Chi_{1}(\vec{x}_{1}) & \ldots & \Chi_{N}(\vec{x}_{1})\\ \vdots & \ddots & \vdots\\ \Chi_{1}(\vec{x}_{N}) & \ldots & \Chi_{N}(\vec{x}_{N})}
\end{equation}
\begin{tikzpicture}[overlay,remember picture]
	\draw[red,->,shorten <=1mm] (A.south) -- ++(-0.2,-0.3) node[below left,yshift=0.2cm] {for normalization};
\end{tikzpicture}

\newpage
One can ultimately show that this is anti-symmetric. Its normalization states
\begin{equation}
\int\Chi^{*}(\vec{x}_{1},\cdots,\vec{x}_{N})\Chi(\vec{x}_{1},\cdots,\vec{x}_{N})\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}=1
\end{equation}

\aside{Ex}{Consider a two-electron Slater determinant. What occurs if the two electrons have opposite spin?
\begin{equation}
\begin{aligned}
\Chi(\vec{x}_{1},\vec{x}_{2})&=\frac{1}{\sqrt{2}}\qty[\Chi_{1}(\vec{x}_{1})\Chi_{2}(\vec{x}_{2})-\Chi_{2}(\vec{x}_{1})\Chi_{1}(\vec{x}_{2})]\\
\Chi_{1}(\vec{x}_{1})&=\Psi_{1}(\vec{r}_{1})\alpha(\omega_{1})\\
\Chi_{2}(\vec{x}_{2})&=\Psi_{2}(\vec{r}_{2})\beta(\omega_{2})
\end{aligned}
\end{equation}
Its probability density as a function of $\vec{r}_{1}$ and $\vec{r}_{2}$ is
\begin{equation}
\begin{aligned}
P(\vec{r}_{1},\vec{r}_{2})&=\int\Chi^{*}(\vec{x}_{1},\vec{x}_{2})\Chi(\vec{x}_{1},\vec{x}_{2})\dd{\omega_{1}}\dd{\omega_{2}}\\
&=\frac{1}{2}\int\qty[\Psi_{1}(\vec{r}_{1})\alpha^{*}(\omega_{1})\Psi_{2}^{*}(\vec{r}_{2})\beta^{*}(\omega_{2})-\Psi_{1}^{*}(\vec{r}_{2})\alpha^{*}(\omega_{2})\Psi_{2}^{*}(\vec{r}_{1})\beta^{*}(\omega_{1})]\\
&\quad\qty[\Psi_{1}(\vec{r}_{1})\alpha(\omega_{1})\Psi_{2}(\vec{r}_{2})\beta(\omega_{2})-\Psi_{1}(\vec{r}_{2})\alpha(\omega_{2})\Psi_{2}(\vec{r}_{1})\beta(\omega_{1})]\dd{\omega_{1}}\dd{\omega_{2}}\\
&=\frac{1}{2}\int\big[\abs{\Psi_{1}(\vec{r}_{1})}^{2}\abs{\Psi_{2}(\vec{r}_{2})}^{2}\abs{\alpha(\omega_{1})}^{2}\abs{\beta(\omega_{2})}^{2}\\
&\quad+\abs{\Psi_{1}(\vec{r}_{2})}^{2}\abs{\Psi_{2}(\vec{r}_{1})}^{2}\abs{\alpha(\omega_{2})}^{2}\abs{\beta(\omega_{1})}^{2}\\
&\quad\tikzmarknode{A}{-}\Psi_{1}^{*}(\vec{r}_{1})\Psi_{1}(\vec{r}_{2})\Psi_{2}^{*}(\vec{r}_{2})\Psi_{2}(\vec{r}_{1})\alpha^{*}(\omega_{1})\beta(\omega_{1})\beta^{*}(\omega_{2})\alpha(\omega_{2}\tikzmarknode{B}{) }\\
&\quad\tikzmarknode{C}{-}\Psi_{1}^{*}(\vec{r}_{2})\Psi_{1}(\vec{r}_{1})\Psi_{2}^{*}(\vec{r}_{1})\Psi_{2}(\vec{r}_{2})\alpha^{*}(\omega_{2})\beta(\omega_{2})\beta^{*}(\omega_{1})\alpha(\omega_{1}\tikzmarknode{D}{)}\big]\dd{\omega_{1}}\dd{\omega_{2}}\\
&=\frac{1}{2}\big[\underbrace{\abs{\Psi_{1}(\vec{r}_{1})}^{2}}_{P_{1}(\vec{r}_{1})}\underbrace{\abs{\Psi_{2}(\vec{r}_{2})}^{2}}_{P_{2}(\vec{r}_{2})}+\abs{\Psi_{1}(\vec{r}_{2})}^{2}\abs{\Psi_{2}(\vec{r}_{1})}^{2}\big]
\end{aligned}
\end{equation}
\begin{tikzpicture}[overlay, remember picture]
	\draw[red,->] (A.south east) -- (B.north east) node[right,yshift=0.2cm] {$0$};
	\draw[red,->] (C.south east) -- (D.north east) node[right,yshift=0.2cm] {$0$};
\end{tikzpicture}This can be interpreted as the average of finding electron 1 at $\vec{r}_{1}$ and electron 2 at $\vec{r}_{2}$ and of finding the same electrons in swapped positions. This form comes from the indistinguishability of electrons.\\

The probability overall came out to be the product of these two individual probabilities. Thus, the motion of the two electrons of opposite spin is uncorrelated.\\

What occurs if the two electrons have the same spin? Following the same algebra, but with replacing $\beta$ with $\alpha$ in $\Chi_{2}$
\begin{equation}
\begin{aligned}
P(\vec{r}_{1},\vec{r}_{2})&=\frac{1}{2}\big[\abs{\Psi_{1}(\vec{r}_{1})}^{2}\abs{\Psi_{2}(\vec{r}_{2})}^{2}+\abs{\Psi_{1}(\vec{r}_{2})}^{2}\abs{\Psi_{2}(\vec{r}_{1})}^{2}]\\
&\quad-\frac{1}{2}\qty[\Psi_{1}^{*}(\vec{r}_{1})\Psi_{1}(\vec{r}_{2})\Psi_{2}^{*}(\vec{r}_{2})\Psi_{2}(\vec{r}_{1})+\Psi_{1}^{*}(\vec{r}_{2})\Psi_{1}(\vec{r}_{1})\Psi_{2}^{*}(\vec{r}_{1})\Psi_{2}(\vec{r}_{2})]
\end{aligned}
\end{equation}
Now the motion of the two electrons with the same spin is correlated.
}

\subsection{Representation of Functions}
In general, we will expand our functions over a complete basis set.
\begin{equation}
\Psi(\vec{r})=\sum_{\alpha=1}^{\infty}c_{\alpha}\phi_{\alpha}(\vec{r})
\end{equation}
where $\{\phi_{\alpha}(\vec{r})\}$ is a complete basis set.\\

Consider a spatial basis set as follows:
\begin{center}
\begin{tikzpicture}
	\draw[->] (0,-1) -- (0,4) node[right] {$\Psi(\vec{r})$};
	\draw[->] (-1,0) -- node[below,text width=4cm,align=center] {\color{red}uniform basis set over grid points of size 1} (7,0) node[right] {$\vec{r}$};
	\draw[blue] plot [smooth] coordinates {(-1,1) (-0.2,2.8) (1,1.9) (1.8,2.1) (2.3,0.9) (3.6,3.1) (5.2,2) (7,3.8)};
	\draw (0,1) node[left] {$1$} -- (0.8,1) -- (0.8,0);
	\draw (2.4,1) -- (2.6,1);
	\foreach \x in {0.2,0.4,0.6,2.4,2.6}{
		\draw (\x,1) -- (\x,0);
	}
	\node at (-0.5,0.5) {$\cdots$};
	\node at (1.6,0.5) {$\cdots$};
	\node at (3.4,0.5) {$\cdots$};
	\node[right] at (7,2) {Example of a real-space basis};
\end{tikzpicture}
\end{center}
One can then express $\Psi(\vec{r})$ as a vector.
\begin{equation}
\begin{aligned}
\Psi(\vec{r})&\equiv \mqty[c_{1} \\ c_{2} \\ \vdots \\ c_{\alpha} \\ \vdots]\\
&\equiv\ket{\Psi}\quad\trm{(Bra-ket notation)}
\end{aligned}
\end{equation}
Note that these vectors will be infinitely long. In practice, these vectors will be truncated at some point.\\

The conjugate transpose is
\begin{equation}
\Psi^{*}(\vec{r})\equiv\mqty[c_{1} & c_{2} & \cdots & c_{\alpha} & \cdots]\equiv\bra{\Psi}
\end{equation}
Operators will be represented as matrices. Given that they correspond with real physical quantities, these matrices will be square Hermitian matrices ($\vb{O}=\vb{O}^{\dagger}$).

\subsection{Hartree-Fock Method}
The idea is to find the best approximation to the ground state of the system in the form of a single Slater determinant.
\begin{equation}
\vb{H}\Chi_{0}=E\Chi_{0}
\end{equation}
where $\Chi_{0}\equiv\Chi_{0}(\vec{x}_{1},\cdots,\vec{x}_{N})$ is the ground state and is given by the equation
\begin{equation}
\Chi_{0}=\frac{1}{\sqrt{N!}}\mdet{\Chi_{1}(\vec{x}_{1}) & \ldots & \Chi_{N}(\vec{x}_{1})\\ \vdots & \ddots & \vdots \\ \Chi_{1}(\vec{x}_{N}) & \ldots & \Chi_{N}(\vec{x}_{N})}
\end{equation}
Note that the Slater determinant does not need to be constructed using single electron wavefunctions 1 to $N$. They simply need to be made from \ul{any} $N$ functions. In our case, we will assume all the $\Chi_{i}$ have been ordered such that we have a good starting point for our ground state. An ``excited" Slater determinant may be constructed using one-electron wavefunctions with higher energy.
\begin{equation}
\Chi=\frac{1}{\sqrt{N!}}\color{red}\underbrace{\color{black}\mdet{\Chi_{i}(\vec{x}_{1}) & \Chi_{j}(\vec{x}_{1}) & \ldots & \Chi_{k}(\vec{x}_{1})\\ \vdots & \vdots & \ddots & \vdots \\ \Chi_{i}(\vec{x}_{N}) & \Chi_{j}(\vec{x}_{N}) & \ldots & \Chi_{k}(\vec{x}_{N})}}_{\trm{determinant of }N\times N\trm{ matrix}}
\end{equation}
Hartree-Fock will transform this problem into
\begin{equation}
\tikzmarknode{A}{F}\Chi_{i}(\vec{x}_{1})=\varepsilon_{i}\Chi_{i}(\vec{x}_{1})
\end{equation}
\begin{tikzpicture}[overlay, remember picture]
	\draw[->,red] (A.south) -- ++ (0.1,-0.3) node[below] {Fock operator};
\end{tikzpicture}

This Fock operator itself will depend on $\{\Chi_{i}(\vec{x}_{1})\}$ that needs to be solved in a self-consistent manner. It will still contain a kinetic term for the electrons and electron-nuclei attraction, but it will transform the electron-electron repulsion into some kind of average electron-electron interaction.

\subsection{Variational Principle}
The variational principle will serve as a guideline for finding the ground-state Slater determinant. The principle states that the expectation value of the Hamiltonian for the system in a trial wave function $\Chi$ that is normalized will be an upper bound to the ground state energy of the $N$ electron system. This transforms our problem into a minimization problem.
\begin{equation}
\mel{\Chi}{\vb{H}}{\Chi}>=E_{0}
\end{equation}
\aside{Proof}{Assume that $\{\phi_{\alpha}(\vec{x}_{1},\cdots,\vec{x}_{N})\}$ is the actual exact solution of the $N$-electron problem.
\begin{equation}
\vb{H}\ket{\phi_{\alpha}}=E_{\alpha}\ket{\phi_{\alpha}},\quad\alpha=0,1,\cdots,N,\cdots
\end{equation}
such that $E_{0}<E_{1}<\cdots<E_{N}<\cdots$.\\

Since $\vb{H}$ is Hermitian, its solutions form a complete orthonormal set. Thus
\begin{equation}
\ket{\Chi}=\sum_{\alpha=0}^{\infty}c_{\alpha}\ket{\phi_{\alpha}}
\end{equation}
Multiplying on the left by $\bra{\phi_{\beta}}$
\begin{equation}
\ip{\phi_{\beta}}{\Chi}=\sum_{\alpha=0}^{\infty}c_{\alpha}\ip{\phi_{\beta}}{\phi_{\alpha}}=\sum_{\alpha=0}^{\infty}c_{\alpha}\delta_{\alpha\beta}=c_{\beta}
\end{equation}
Thus
\begin{equation}
\ket{\Chi}=\sum_{\alpha=0}^{\infty}\ip{\phi_{\alpha}}{\Chi}\ket{\phi_{\alpha}}=\underbrace{\sum_{\alpha=0}^{\infty}\op{\phi_{\alpha}}{\phi_{\alpha}}}_{\textstyle\id}\ket{\Chi}
\end{equation}
Calculating the expectation value
\begin{equation}
\begin{aligned}
\mel{\Chi}{\vb{H}}{\Chi}&=\qty(\sum_{\alpha=0}^{\infty}\ip{\Chi}{\phi_{\alpha}}\bra{\phi_{\alpha}})\vb{H}\qty(\sum_{\beta=0}^{\infty}\ket{\phi_{\beta}}\ip{\phi_{\beta}}{\Chi})\\
&=\sum_{\alpha=0}^{\infty}\sum_{\beta=0}^{\infty}\ip{\Chi}{\phi_{\alpha}}\mel{\phi_{\alpha}}{\vb{H}}{\phi_{\beta}}\ip{\phi_{\beta}}{\Chi}\\
&=\sum_{\alpha=0}^{\infty}\sum_{\beta=0}^{\infty}E_{\beta}\ip{\Chi}{\phi_{\alpha}}\underbrace{\ip{\phi_{\alpha}}{\phi_{\beta}}}_{\delta_{\alpha\beta}}\ip{\phi_{\beta}}{\Chi}\\
&=\sum_{\alpha=0}^{\infty}E_{\alpha}\ip{\Chi}{\phi_{\alpha}}\ip{\phi_{\alpha}}{\Chi}\\
&=\sum_{\alpha=0}^{\infty}E_{\alpha}\abs{\ip{\Chi}{\phi_{\alpha}}}^{2}\\
&\geq E_{0}\sum_{\alpha=0}^{\infty}\abs{\ip{\Chi}{\phi_{\alpha}}}^{2}
\end{aligned}
\end{equation}
Moreover, following a similar procedure
\begin{equation}
\ip{\Chi}{\Chi}=\sum_{\alpha=0}^{\infty}\abs{\ip{\Chi}{\phi_{\alpha}}}^{2}=1
\end{equation}
Thus
\begin{equation}
\mel{\Chi}{\vb{H}}{\Chi}\geq E_{0}
\end{equation}
}

\subsection{Expectation Value of Hamiltonian for Single Slater Determinant}
Let us now work out $\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}$ for $\ket{\Chi_{0}}$ being a single Slater determinant. Recall that
\begin{equation}
\vb{H}=\underbrace{\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}+\sum_{i=1}^{N}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}}}_{\vb{O}_{1}=\sum_{i=1}^{N}\vb{h}(i)}+\underbrace{\sum_{i=1}^{N}\sum_{j>i}^{N}\frac{1}{r_{ij}}}_{\vb{O}_{2}}
\end{equation}
Thus
\begin{equation}
\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}=\mel{\Chi_{0}}{\vb{O}_{1}}{\Chi_{0}}+\mel{\Chi_{0}}{\vb{O}_{2}}{\Chi_{0}}
\end{equation}
The first term is
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}&=\mel{\Chi_{0}}{[\vb{h}(1)+\vb{h}(2)+\ldots+\vb{h}(N)]}{\Chi_{0}}\\
&=N\mel{\Chi_{0}}{\vb{h}(1)}{\Chi_{0}}\qq{(since $1,\cdots,N$ are just dummy variables)}\\
&=\frac{N}{\sqrt{N!}}\int\Bigg[\sum_{n-1}^{N!}(-1)^{n+1}\perm_{n}\{\Chi_{1}^{*}(\vec{x}_{1})\Chi_{2}^{*}(\vec{x}_{2})\ldots\Chi_{N}^{*}(\vec{x}_{N})\}\vb{h}(1)\\
&\quad\quad\frac{1}{\sqrt{N!}}\sum_{m=1}^{N!}(-1)^{m+1}\perm_{m}\{\Chi_{1}(\vec{x}_{1})\Chi_{2}(\vec{x}_{2})\ldots\Chi_{N}(\vec{x}_{N})\}\Bigg]\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}\\
&=\frac{1}{(N-1)!}\int\Bigg[\sum_{n=1}^{N!}\sum_{m=1}^{N!}(-1)^{m+n+2}\perm_{n}\{\Chi_{1}^{*}(\vec{x}_{1})\Chi_{2}^{*}(\vec{x}_{2})\ldots\Chi_{N}^{*}(\vec{x}_{N})\}\vb{h}(1)\\
&\qquad\qquad\qquad\qquad\perm_{m}\{\Chi_{1}(\vec{x}_{1})\Chi_{2}(\vec{x}_{2})\ldots\Chi_{N}(\vec{x}_{N})\}\Bigg]\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}
\end{aligned}
\end{equation}
where $\perm_{n}$ denotes the $n$-th permutation. By orthonormality of $\{\Chi_{i}(\vec{x}_{i})\}$, in the above terms, $\vec{x}_{2},\cdots,\vec{x}_{N}$ must be in the same one-electron function in both permutations for that term to be non-zero. Thus, $\vec{x}_{1}$ will also have one choice left. Moreover, $\perm_{n}$ and $\perm_{m}$ must be the same permutation.
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}}{\vb{O}_{1}}{\Chi_{0}}&=\frac{1}{(N-1)!}\sum_{n=1}^{N}\int\Chi_{n}^{*}(\vec{x}_{1})\vb{h}(1)\Chi_{n}(\vec{x}_{1})\dd{\vec{x}_{1}}\,(N-1)!\\
&=\sum_{n=1}^{N}\int\Chi_{n}^{*}(\vec{x}_{1})\vb{h}(1)\Chi_{n}(\vec{x}_{1})\dd{\vec{x}_{1}}\\
&=\sum_{n=1}^{N}\mel{\Chi_{n}}{\vb{h}}{\Chi_{n}}\qq{or}\color{red}\underbrace{\color{black}\sum_{n=1}^{N}\,[n|\vb{h}|n]}_{\trm{chemistry notation}}
\end{aligned}
\end{equation}
The second term is
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}}{\vb{O}_{2}}{\Chi_{0}}&=\mel{\Chi_{0}}{\qty[\frac{1}{r_{12}}+\frac{1}{r_{13}}+\ldots+\frac{1}{r_{n-1,n}}]}{\Chi_{0}}\\
&=\frac{N!}{2!(N-2)!}\mel{\Chi_{0}}{\frac{1}{r_{12}}}{\Chi_{0}}\\
&=\frac{N!}{2!(N-2)!}\int\Bigg[\sum_{n=1}^{N!}\sum_{m=1}^{N!}\qty(\frac{1}{\sqrt{N!}})\qty(\frac{1}{\sqrt{N!}})(-1)^{n-1}(-1)^{m+1}\\
&\quad\perm_{n}\{\Chi_{1}^{*}(\vec{x}_{1})\ldots\Chi_{N}^{*}(\vec{x}_{N})\}\frac{1}{r_{12}}\perm_{m}\{\Chi_{1}(\vec{x}_{1})\ldots\Chi_{N}(\vec{x}_{N})\}\Bigg]\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}
\end{aligned}
\end{equation}
For a given term to be non-zero, $\vec{x}_{j}$ for $j\neq1,2$ has to be in the same $\Chi_{i}$ in both permutations $n$ and $m$ due to orthonormality $\qty(\int\Chi_{k}^{*}(\vec{x}_{j})\Chi_{\ell}(\vec{x}_{j})\dd{\vec{x}_{j}}=\delta_{k\ell})$. Thus
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}}{\vb{O}_{2}}{\Chi_{0}}&=\frac{1}{2(N-2)!}\sum_{n=1}^{N}\sum_{m\neq n}^{N}\bigg[\int(-1)^{\tikzmarknode{A}{n}+1+m+1}\Chi_{n}^{*}(\vec{x}_{1})\Chi_{m}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{n}(\vec{x}_{1})\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{1}}\dd{\vec{x}_{2}}\\
&\quad+\int(-1)^{n+1+m+1}\Chi_{n}^{*}(\vec{x}_{1})\Chi_{m}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{n}(\vec{x}_{2})\Chi_{m}(\vec{x}_{1})\dd{\vec{x}_{1}}\dd{\vec{x}_{2}}\bigg]\\
&\quad(N-2)\tikzmarknode{B}{!}\\
&=\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\bigg[\int\Chi_{n}^{*}(\vec{x}_{1})\Chi_{m}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{n}(\vec{x}_{1})\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{1}}\dd{\vec{x}_{2}}\\
&\quad-\int\Chi_{n}^{*}(\vec{x}_{1})\Chi_{m}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{n}(\vec{x}_{2})\Chi_{m}(\vec{x}_{1})\dd{\vec{x}_{1}}\dd{\vec{x}_{2}}\bigg]\\
&\equiv\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\qty[\ip{nm}{nm}-\ip{nm}{mn}]\\
&=\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\bigg[\int\Chi_{n}^{*}(\vec{x}_{1})\Chi_{n}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{1}}\dd{\vec{x}_{2}}\\
&\quad-\int\Chi_{n}^{*}(\vec{x}_{1})\Chi_{m}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{n}(\vec{x}_{2})\dd{\vec{x}_{1}}\dd{\vec{x}_{2}}\bigg]\\
&\equiv\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\big(\color{red}\underbrace{\color{black}[nn|mm]}_{\trm{Coulomb}}{\color{black}-}\underbrace{\color{black}[nm|mn]}_{\trm{exchange}}\color{black}\big)
\end{aligned}
\end{equation}
\begin{tikzpicture}[overlay,remember picture]
	\draw[red,<-,shorten <=1mm] (A.north) -- ++(0,0.5) node[above] {even since they are in the same permutation};
	\draw[red,<-,shorten <=1mm] (B.east) -- ++(0.3,0) node[right] {arises from the possibility of putting $\vec{x}_{j}$ in the remaining $\Chi_{i}$ functions};
\end{tikzpicture}
\newpage
Thus
\begin{equation}
\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}=\sum_{n=1}^{N}[n|\vb{h}|n]+\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\big([nn|mm]\tikzmarknode{A}{-}[nm|mn]\big)
\end{equation}
\begin{tikzpicture}[overlay,remember picture]
	\draw[red,<-,shorten <=2mm] (A.north) -- ++(0,0.6) node[above] {minimize this!};
\end{tikzpicture}
\subsection{Minimization and Lagrange Method of Undetermined Multipliers}
Note that the previous result for $\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}$ requires the orthonormality of the trial function used to build the Slater determinant $\ket{\Chi_{0}}$. Thus, varying the trial functions while following the variational principle becomes a constrained minimization problem. This can be tackled using the Lagrange method of undetermined multipliers.\\

Let us consider an example. Imagine a function $f(x,y)$ that is to be the subject of minimization following the constraint $g(x,y)=C$.
\begin{center}
\begin{tikzpicture}
	\draw[->] (-1,0) -- (8,0) node[right] {$x$};
	\draw[->] (0,-1) -- (0,5) node[above] {$y$};
	\filldraw[black] (4.5,3) circle (3pt);
	\draw[rotate around={20:(4.5,3)}] (4.5,3) ellipse (30pt and 15pt);
	\draw[rotate around={20:(4.5,3)}] (4.5,3) ellipse (60pt and 30pt);
	\draw[rotate around={20:(4.5,3)}] (4.5,3) node[below left,yshift=-2cm] {contour lines} ellipse (90pt and 45pt);
	\draw[rotate around={20:(4.5,3)},red,dashed] (4.5,3) ellipse (75pt and 37.5pt);
	\filldraw[red] (7,3.5) circle (3pt);
	\draw[red] (4,-1) .. controls (4,1) and (6.5,0) .. (7.35,5) node[right] {$g(x,y)=C$};
	\draw[red,<-] (7.5,3) -- (8,2.5) node[right] {This is the actual point of interest.};
\end{tikzpicture}
\end{center}
Thus
\begin{equation}
\begin{cases}
g(x,y)-C=0\\
\nabla f \propto \nabla g \qq{\color{red}(since they're tangential to the contour)}
\end{cases}
\end{equation}
Let us define
\begin{equation}
\begin{aligned}
\mathcal{L}&=f(x,y)-\color{red}\underbrace{\color{black}\lambda}_{\mathclap{\substack{\trm{undetermined}\\\trm{multiplier}}}}\color{black}\qty(g(x,y)-C)\\
\implies \var{\mathcal{L}}&=\pdv{f}{x}\var{x}+\pdv{f}{y}\var{y}-\lambda\qty(\pdv{g}{x}\var{x}+\pdv{g}{y}\var{y})-\qty(g(x,y)-C)\var{\lambda}
\end{aligned}
\end{equation}
By setting $\var{\mathcal{L}}=0$, since the variations $\var{x}$, $\var{y}$, and $\var{\lambda}$ are independent, all of their coefficients must vanish.
\begin{empheq}[left=\implies\empheqlbrace]{align}
\qty(\pdv{f}{x}-\lambda\pdv{g}{x})&=0\\
\qty(\pdv{f}{y}-\lambda\pdv{g}{y})&=0\\
\qty(g(x,y)-C)&=0
\end{empheq}
Note that the first two equations is equivalent to the condition $\nabla f\propto \nabla g$.

\subsection{Hartree-Fock Equation}
The ground-state energy is now given by
\begin{equation}
E_{0}=\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}=\sum_{n=1}^{N}{\color{red}\underbrace{\color{black}[n|\vb{h}|n]}_{\trm{1-electron}}}+\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\big({\color{red}\underbrace{\color{black}[nn|mm]}_{\trm{Coulomb}}}-{\color{red}\underbrace{\color{black}[nm|mn]}_{\trm{exchange}}}\big)
\end{equation}
Let us minimize $E_{0}$ subject to the constraint that $\{n\}$ is orthnormal (i.e. $[n|m]=\delta_{nm}$).
\begin{equation}
\mathcal{L}=E_{0}-\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{nm}\qty([n|m]-\delta_{nm})
\end{equation}
We want to obtain $\var{\mathcal{L}}=0$. The trial functions will vary from $\{\Chi_{n}\}\rightarrow\{\Chi_{n}+\var{\Chi_{n}}\}$, which we denote in shorthand as $\{n\}\rightarrow\{n+\var{n}\}$.
\begin{center}
\begin{tikzpicture}
	\draw[->] (0,-1) -- (0,4) node[right] {$\Chi_{n}(\vec{x}_{1})$};
	\draw[<->] (-4,0) -- (4,0) node[right] {$\vec{x}_{1}$};
	\draw[blue] plot [smooth] coordinates {(-4,0.8) (-3,1.4) (-2.2,2.1) (-1.5,1.4) (-0.2,0.7) (1.5,1.7) (3.2,3.5) (4,2.5)};
	\draw[red] plot [smooth] coordinates {(-4,0.8) (-2.9,1.35) (-2.1,2.05) (-1.4,1.4) (-0.1,0.7) (1.7,1.7) (3.4,3.4) (4,2.6)};
	\node[right,red] at (4,2.6) {$\Chi_{n}(\vec{x}_{1})+\underbrace{\var{\Chi_{n}(\vec{x}_{1})}}_{\mathclap{\trm{small arbitrary function}}}$};
\end{tikzpicture}
\end{center}
Thus
\begin{equation}
\begin{aligned}
\var{[n|\vb{h}|n]}&=[(n+\var{n})|\vb{h}|(n+\var{n})]-[n|\vb{h}|n]\\
&=\int\qty(\Chi_{n}^{*}(\vec{x}_{1})+\var{\Chi_{n}^{*}(\vec{x}_{1})})\vb{h}(1)\qty(\Chi_{n}(\vec{x}_{1})+\var{\Chi_{n}(\vec{x}_{1})})\dd{\vec{x}_{1}}\\
&\quad-\int\Chi_{n}^{*}(\vec{x}_{1})\vb{h}(1)\Chi_{n}(\vec{x}_{1})\dd{\vec{x}_{1}}\\
&=\int\var{\Chi_{n}^{*}(\vec{x}_{1})}\vb{h}(1)\Chi_{n}(\vec{x}_{1})\dd{\vec{x}_{1}}+\int\Chi_{n}^{*}(\vec{x}_{1})\vb{h}(1)\var{\Chi_{n}(\vec{x}_{1})}\dd{\vec{x}_{1}}\\
&\quad+\int\var{Chi_{n}^{*}(\vec{x}_{1})}\vb{h}(1)\var{\Chi_{n}(\vec{x}_{1})}\dd{\vec{x}_{1}}
\end{aligned}
\end{equation}
In the limit of $\var{\Chi_{n}(\vec{x}_{1})}$ going to zero, the above expression simplifies to
\begin{equation}
\begin{aligned}
\var{[n|\vb{h}|n]}&=\int\var{\Chi_{n}^{*}(\vec{x}_{1})}\vb{h}(1)\Chi_{n}(\vec{x}_{1})\dd{\vec{x}_{1}}+\int\Chi_{n}^{*}(\vec{x}_{1})\vb{h}(1)\var{\Chi_{n}(\vec{x}_{1})}\dd{\vec{x}_{1}}\\
&=[\var{n}|\vb{h}|n]+[n|\vb{h}|\var{n}]
\end{aligned}
\end{equation}
For the Coulomb portion
\begin{equation}
\var{[nn|mm]}=\ldots=[\var{n}n|mm]+[n\var{n}|mm]+[nn|\var{m}m]+[nn|m\var{m}]
\end{equation}
The exchange portion is
\begin{equation}
\var{[nm|mn]}=\ldots=[\var{n}m|mn]+[n\delta{m}|mn]+[nm|\delta{m}n]+[nm|m\delta{n}]
\end{equation}
Thus
\begin{equation}
\begin{aligned}
\var{\mathcal{L}}&=\sum_{n=1}^{N}\qty([\var{n}|\vb{h}|n])+\sum_{n=1}^{N}\sum_{m=1}^{N}\qty([\var{n}n|mm]-[\delta{n}m|mn])\\
&\quad-\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{nm}[\var{n}|m]+\qcc*
\end{aligned}
\end{equation}
Setting $\var{L}=0$
\begin{equation}
\begin{aligned}
0&=\sum_{n=1}^{N}\bigg[\int\underline{\var{\Chi_{n}^{*}(\vec{x}_{1})}}\vb{h}(1)\Chi_{n}(\vec{x}_{1})\underline{\dd{\vec{x}_{1}}}+\sum_{m=1}^{N}\bigg(\int\underline{\var{\Chi_{n}^{*}(\vec{x}_{1})}}\Chi_{n}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{m}(\vec{x}_{2})\underline{\dd{\vec{x}_{1}}}\dd{\vec{x}_{2}}\\
&\quad-\int\underline{\var{\Chi_{n}^{*}(\vec{x}_{1})}}\Chi_{m}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{n}(\vec{x}_{2})\underline{\dd{\vec{x}_{1}}}\dd{\vec{x}_{2}}\bigg)\\
&\quad-\sum_{m=1}^{N}\int\underline{\var{\Chi_{n}^{*}(\vec{x}_{1})}}\Chi_{m}(\vec{x}_{1})\underline{\dd{\vec{x}_{1}}}\bigg]+\qcc*
\end{aligned}
\end{equation}
Since the underlined factors above are common to all integrals
\begin{equation}
\begin{aligned}
0&=\sum_{n=1}^{N}\Bigg[\int\var{\Chi_{n}^{*}(\vec{x}_{1})}\dd{\vec{x}_{1}}\bigg[\vb{h}(1)\Chi_{n}(\vec{x}_{1})+\sum_{n=1}^{N}\bigg(\int\Chi_{n}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&\quad-\int\Chi_{m}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{n}(\vec{x}_{2})\dd{\vec{x}_{2}}\bigg)-\sum_{m=1}^{N}\lambda_{nm}\Chi_{m}(\vec{x}_{1})\bigg]\Bigg]
\end{aligned}
\end{equation}
Since $\var{\Chi_{n}(\vec{x}_{1})}$ are arbitrary functions and $\var{\Chi_{n}(\vec{x}_{1})}$ are completely independent of each other for different $n$
\begin{equation}
\begin{aligned}
\sum_{m=1}^{N}\lambda_{nm}\Chi_{m}(\vec{x}_{1})&=\vb{h}(1)\Chi_{n}(\vec{x}_{1})+\sum_{m=1}^{N}\bigg[\int\Chi_{n}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&\quad-\int\Chi_{m}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{n}(\vec{x}_{2})\dd{\vec{x}_{2}}\bigg]
\end{aligned}
\end{equation}
Let us define
\begin{equation}
\begin{aligned}
{\color{red}\underbrace{\color{black}\vb{J}_{m}(\vec{x}_{1})}_{\mathclap{\substack{\trm{Coulomb operator $m$}\\\trm{(local)}}}}}\Chi_{n}(\vec{x}_{1})&=\int\Chi_{n}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&=\qty(\int\Chi_{m}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{m}(\vec{x}_{2})\dd{\vec{x}_{2}})\Chi_{n}(\vec{x}_{1})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
{\color{red}\underbrace{\color{black}\vb{K}_{m}(\vec{x}_{1})}_{\mathclap{\substack{\trm{Exchange operator $m$}\\\trm{(non-local)}}}}}\Chi_{n}(\vec{x}_{1})&=\int\Chi_{m}(\vec{x}_{1})\frac{1}{r_{12}}\Chi_{m}^{*}(\vec{x}_{2})\Chi_{n}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&=\qty(\int\Chi_{m}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{n}(\vec{x}_{2})\dd{\vec{x}_{2}})\Chi_{m}(\vec{x}_{1})
\end{aligned}
\end{equation}
Thus
\begin{equation}
\bigg[\underbrace{\vb{h}(1)+\sum_{m=1}^{N}\qty(\vb{J}_{m}(1)-\vb{K}_{m}(1))}_{\vb{F}(\vec{x}_{1})\,:\,\trm{Fock operator (non-local operator)}}\bigg]\Chi_{n}(\vec{x}_{1})=\sum_{m=1}^{N}\lambda_{nm}\Chi_{m}(\vec{x}_{1})
\end{equation}
\begin{equation}
\implies \vb{F}(\vec{x}_{1})\Chi_{n}(\vec{x}_{1})=\sum_{m=1}^{N}\lambda_{nm}\Chi_{m}(\vec{x}_{1})\qq{(Hartree-Fock equation)}
\end{equation}
To recap, we cast
\begin{equation}
\vb{H}\Chi=E\tikzmarknode{Chi}{\Chi}
\end{equation}
\begin{tikzpicture}[overlay,remember picture]
	\draw[red,->,shorten <=1mm] (Chi.east) -- +(0.5,0) node[right] {\trm{many-electron wavefunction}};
\end{tikzpicture}
into
\begin{equation}
\vb{F}\tikzmarknode{Chi_n}{\Chi_{n}}=\sum_{m=1}^{N}\lambda_{nm}\Chi_{m}
\end{equation}
\begin{tikzpicture}[overlay,remember picture]
	\draw[red,->,shorten <=1mm] (Chi_n.north) -- +(0.5,0.5) node[above right] {\trm{one-electron wavefunction}};
\end{tikzpicture}
where $\vb{F}(\vec{x}_{1})$ depend on the one-electron functions themselves (which are the solutions that we are after). This equation needs to be done iteratively in a self-consistent manner. We will start with a one-electron wavefunction, build the Coulomb and exchange operators, and then solve for the new one-electron wavefunctions.

\subsection{Unitary Transformations on Hartree-Fock Solutions}
The Hartree-Fock equation contains an $N\times N$ matrix $\lambda_{nm}$. The equation can be greatly simplified by transforming $\lambda_{nm}$ into a diagonal matrix.\\

Let us define
\begin{equation}
\vb{A}=\mqty[\Chi_{1}(\vec{x}_{1}) & \ldots & \Chi_{N}(\vec{x}_{1})\\ \vdots & \ddots & \vdots \\ \Chi_{1}(\vec{x}_{N}) & \ldots & \Chi_{N}(\vec{x}_{N})]
\end{equation}
such that $\Chi_{0}(\vec{x}_{1},\cdots,\vec{x}_{N})=\frac{1}{\sqrt{N!}}\det(\vb{A})$.\\

One can also define
\begin{equation}
\vb{A}^{\prime}=\mqty[\Chi_{1}^{\prime}(\vec{x}_{1}) & \ldots & \Chi_{N}^{\prime}(\vec{x}_{1})\\ \vdots & \ddots & \vdots \\ \Chi_{1}^{\prime}(\vec{x}_{N}) & \ldots & \Chi_{N}^{\prime}(\vec{x}_{N})]
\end{equation}
such that $\Chi_{0}^{\prime}(\vec{x}_{1},\cdots,\vec{x}_{N})=\frac{1}{\sqrt{N!}}\det(\vb{A}^{\prime})$.\\

\newpage
Assume that $\vb{A}^{\prime}$ is built from $\vb{A}$ using a unitary transformation.
\begin{equation}
\begin{aligned}
\vb{A}^{\prime}&=\vb{A}\vb{U}\\
\implies\mqty[\Chi_{1}^{\prime}(\vec{x}_{1}) & \ldots & \Chi_{N}^{\prime}(\vec{x}_{1})\\ \vdots & \ddots & \vdots \\ \Chi_{1}^{\prime}(\vec{x}_{N}) & \ldots & \Chi_{N}^{\prime}(\vec{x}_{N})]&=\mqty[\Chi_{1}(\vec{x}_{1}) & \ldots & \Chi_{N}(\vec{x}_{1})\\ \vdots & \ddots & \vdots \\ \Chi_{1}(\vec{x}_{N}) & \ldots & \Chi_{N}(\vec{x}_{N})]\mqty[U_{11} & \ldots & U_{1N} \\ \vdots & \ddots & \vdots \\ U_{N1} & \ldots & U_{NN}]
\end{aligned}
\end{equation}
with $\vb{U}$ being unitary (i.e. $\vb{U}^{\dagger}\vb{U}=\id$).\\

Evaluating the probability density
\begin{equation}
\begin{aligned}
\ip{\Chi_{0}^{\prime}}{\Chi_{0}^{\prime}}&=\frac{1}{\sqrt{N!}}\qty(\det\vb{A}^{\prime})^{*}\frac{1}{\sqrt{N!}}\qty(\det\vb{A}^{\prime})\\
&=\frac{1}{N!}\qty(\det\vb{A}^{\prime\dagger})\qty(\det\vb{A}^{\prime})\\
&=\frac{1}{N!}\det\qty(\vb{A}^{\prime}\vb{A}^{\prime\dagger})\\
&=\frac{1}{N!}\det(\vb{A}\vb{U}\vb{U}^{\dagger}\vb{A}^{\dagger})\\
&=\frac{1}{N!}\det\qty(\vb{A}\vb{A}^{\dagger})\\
&=\ip{\Chi_{0}}{\Chi_{0}}
\end{aligned}
\end{equation}
Thus, for two sets $\{\Chi_{n}\}$ and $\{\Chi_{n}^{\prime}\}$ that are related by a unitary transformation, the physics of the problem remains the same.

\newpage
\subsection{Effect of Unitary Transformation on Fock Operator}
Note that $\vb{F}(\vec{x}_{1})$ contains the solutions $\Chi_{n}(\vec{x}_{1})$ which will be under a unitary transformation.
\begin{equation}
h^{\prime}(1)=\vb{h}(1)
\end{equation}
\begin{equation}
\begin{aligned}
\sum_{m=1}^{N}\vb{J}_{m}^{\prime}(1)&=\sum_{m=1}^{N}\int\Chi_{m}^{\prime *}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{m}^{\prime}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&=\sum_{m=1}^{N}\int\qty(\sum_{i=1}^{N}\Chi_{i}^{*}(\vec{x}_{2})U_{im}^{*})\frac{1}{r_{12}}\qty(\sum_{j=1}^{N}\Chi_{j}(\vec{x}_{2})U_{jm})\dd{\vec{x}_{2}}\\
&=\sum_{i=1}^{N}\sum_{j=1}^{N}\sum_{m=1}^{N}U_{jm}U_{im}^{*}\int\Chi_{i}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{j}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&=\sum_{i=1}^{N}\sum_{j=1}^{N}{\color{red}\underbrace{\color{black}\sum_{m=1}^{N}U_{jm}U_{mi}^{*}}_{(\vb{U}\vb{U}^{\dagger})_{ji}=\delta_{ji}}}\int\Chi_{i}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{j}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&=\sum_{i=1}^{N}\int\Chi_{i}^{*}(\vec{x}_{2})\frac{1}{r_{12}}\Chi_{i}(\vec{x}_{2})\dd{\vec{x}_{2}}\\
&=\sum_{i=1}^{N}J_{i}(1)
\end{aligned}
\end{equation}
A similar derivation will show that the exchange portion of the Fock operator does not change under a unitary transformation. Thus, the Fock operator does not change under the unitary transformation.

\subsection{Canonical Hartree-Fock Equation}
The Hartree-Fock equation is
\begin{equation}
\vb{F}\ket{\Chi_{n}}=\sum_{m=1}^{N}\lambda_{nm}\ket{\Chi_{m}}
\end{equation}
By orthonormality
\begin{equation}
\lambda_{nm}=\mel{\Chi_{m}}{\vb{F}}{\Chi_{n}}
\end{equation}
For the constants under a unitary transformation
\begin{equation}
\begin{aligned}
\lambda_{nm}^{\prime}&=\mel{\Chi_{m}^{\prime}}{\vb{F}^{\prime}}{\Chi_{n}^{\prime}}\\
&=\int\Chi_{m}^{\prime}(\vec{x}_{1})\vb{F}^{\prime}(\vec{x}_{1})\Chi_{n}^{\prime}(\vec{x}_{1})\dd{\vec{x}_{1}}\\
&=\int\qty(\sum_{i=1}^{N}\Chi_{i}^{*}(\vec{x}_{1})U_{im}^{*})\vb{F}(\vec{x}_{1})\qty(\sum_{j=1}^{N}\Chi_{j}(\vec{x}_{1})U_{jn})\dd{\vec{x}_{1}}\\
&=\sum_{i=1}^{N}\sum_{j=1}^{N}U_{im}^{*}U_{jn}{\color{red}\underbrace{\color{black}\int\Chi_{i}^{*}(\vec{x}_{1})\vb{F}(\vec{x}_{1})\Chi_{j}(\vec{x}_{1})\dd{\vec{x}_{1}}}_{\lambda_{ji}}}\\
&=\sum_{i=1}^{N}\sum_{j=1}^{N}U_{jn}\lambda_{ji}U_{im}^{*}\\
&=\qty(\vb{U}^{\dagger}\vb{\lambda}\vb{U})^{*}_{nm}
\end{aligned}
\end{equation}
There exists a unitary transformation $\vb{U}$ that diagonalizes $\lambda_{nm}$. Among all possible sets of solutions $\{\Chi_{n}\}$, there exists one for which $\lambda_{nm}$ is diagonal. Given the physical equivalence of different sets of solutions, we will choose to work with the set for which $\lambda_{nm}$ is diagonal. Thus
\begin{equation}
\vb{F}(\vec{x}_{1})\Chi_{n}(\vec{x}_{1})=\lambda_{n}\Chi_{n}(\vec{x}_{1})\qq{(or $\vb{F}\ket{\Chi_{n}}=\lambda_{n}\ket{\Chi_{n}}$)}
\end{equation}
This is the canonical form of the Hartree-Fock equation.

\subsection{Koopmans' Theorem}
After obtaining the solutions for $\ket{\Chi_{n}}$, we obtain the $n$ one-electron functions with the lowest energy to construct the ground-state Slater determinant.\\

Consider $\lambda_{n}$
\begin{equation}
\begin{aligned}
\lambda_{n}&=\mel{\Chi_{n}}{\vb{F}}{\Chi_{n}}=\ldots=[n|\vb{h}|n]+\sum_{m=1}^{N}\qty([nn|mm]-[nm|mn])\\
\implies \sum_{n=1}^{N}\lambda_{n}&=\sum_{n=1}^{N}[n|\vb{h}|n]+\sum_{n=1}^{N}\sum_{m=1}^{N}\qty([nn|mm]-[nm|mn])
\end{aligned}
\end{equation}
Let us also recall the ground-state energy.
\begin{equation}
\begin{aligned}
E_{0}&=\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}\\
&=\sum_{n=1}^{N}[n|\vb{h}|n]+\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\qty([nn|mm]-[nm|mn])
\end{aligned}
\end{equation}
While similar, $\sum_{n=1}^{N}\lambda_{n}\neq E_{0}$. One should not immediately associate $\lambda_{n}$ as energies. Moreover, one should be aware that $\Chi_{n}$ are not physical objects by themselves.\\

Koopmans' theorem states that considering a system of $N$ electrons, if one takes one of the filled one-electron levels ($\lambda_{f}$), then $\lambda_{f}$ is the negative of the ionization potential corresponding to an electron in that level. This however assumes that the other levels and functions do not change as a result of such an ionization event.
\begin{center}
\begin{tikzpicture}
	\draw (0,0) -- (4,0) node[right] {\footnotesize1};
	\draw (0,0.5) -- (4,0.5) node[right] {\footnotesize2};
	\draw (0,1) -- (4,1) node[right] {\footnotesize3};
	\draw (0,1.5) -- (4,1.5) node[right,xshift=0.05cm,yshift=0.1cm] {\footnotesize\vdots};
	\draw (0,2) -- (4,2);
	\draw (0,2.5) -- (4,2.5);
	\draw (0,3) -- (4,3);
	\filldraw[black] (2,0) circle (2pt);
	\filldraw[black] (2,0.5) circle (2pt);
	\filldraw[black] (2,1) circle (2pt);
	\filldraw[black] (2,1.5) circle (2pt);
	\filldraw[black] (2,2) circle (2pt);
	\filldraw[black] (2,2.5) circle (2pt);
	\filldraw[black] (2,3) circle (2pt);
	\draw[decorate,decoration={brace,amplitude=10pt}] (-0.5,0) -- (-0.5,3) node[left,midway,xshift=-0.5cm] {$N$};
	\node[above] at (2,3.5) {$\vdots$};
	\draw[<-,shorten <=1mm] (4,2.5) -- (4.5,3) node[above right] {$\lambda_{f}$};
	\node[right,red,text width=5cm] at (6,3) {$\lambda_{f}$ $\uparrow$, assuming that removing this electron does not change the other levels and functions};
\end{tikzpicture}
\end{center}

\aside{Proof}{Consider a system of $N$ electrons with wavefunction $\tensor*[^{N}]{\ket{\Chi}}{}$ and energy $\tensor*[^{N}]{E}{_{0}}$. Let us say that the system with $N-1$ electrons is described by $\tensor*[^{N-1}]{\ket{\Chi}}{}$ and $\tensor*[^{N-1}]{E}{_{0}}$.\\

The ionization potential is $\tensor*[^{N-1}]{E}{_{0}}-\tensor*[^{N}]{E}{_{0}}$. Thus
\begin{equation}
\begin{aligned}
\tensor*[^{N-1}]{E}{_{0}}-\tensor*[^{N}]{E}{_{0}}&=\sum_{\substack{n=1\\n\neq f}}^{N}[n|\vb{h}|n]+\frac{1}{2}\sum_{\substack{n=1 \\ n\neq f}}^{N}\sum_{\substack{m=1 \\ m\neq f}}^{N}\qty([nn|mm]-[nm|mn])\\
&\quad-\sum_{n=1}^{N}[n|\vb{h}|n]-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\qty([nn|mm]-[nm|mn])\\
&=-[f|\vb{h}|f]-\frac{1}{2}\sum_{n=1}^{N}\qty([nn|ff]-[nf|fn])\\
&\quad-\frac{1}{2}\sum_{m=1}^{N}\qty([ff|mm]-[fm|mf])\\
&=-[f|\vb{h}|f]-\sum_{m=1}^{N}\qty([ff|mm]-[fm|mf])\\
&=-\lambda_{f}
\end{aligned}
\end{equation}
Similarly, if $\lambda_{e}$ corresponds to an empty level, one can show that it represents the negative of an electron affinity (within the same assumption as before).
\begin{equation}
\tensor*[^{N+1}]{E}{_{0}}-\tensor*[^{N}]{E}{_{0}}=\ldots=\lambda_{e}
\end{equation}
}
This theorem gives (approximate) physical legitimacy to $\{\lambda_{n}\}$ and $\{\Chi_{n}\}$. From now on, we call $\{\Chi_{n}\}$ \ul{spin orbitals}.  We will also use $\{\varepsilon_{n}\}$ instead of $\{\lambda_{n}\}$.

\subsection{Spatial Form of the Hartree-Fock Equation}
The Hartree-Fock equation is
\begin{equation}
\vb{F}(\vec{x}_{1})\Chi_{n}(\vec{x}_{1})=\varepsilon_{n}\Chi_{n}(\vec{x}_{1})
\end{equation}
where
\begin{equation}
\Chi_{n}(\vec{x}_{1})=\begin{cases}
\Psi_{n\alpha}(\vec{r}_{1})\alpha(\omega_{1}) \qq{or}\\
\Psi_{n\beta}(\vec{r}_{1})\beta(\omega_{1})
\end{cases}
\end{equation}
In order to come up with an implementation of Hartree-Fock, we divide this equation into two possibilities.\\

For restricted Hartree-Fock (RHF), one assumes that spin orbitals come in pairs and that the spatial part remains the same (i.e. $\Psi_{n\alpha}(\vec{r}_{1})=\Psi_{n\beta}(\vec{r}_{1})$). This may work well for systems with paired electrons. Alternatively, for unrestricted Hartree-Fock (UHF), one does not have the above assumption. One can use either RHF or UHF for both close-shell (even $N$) or open-shell (odd $N$) systems.\\

Let us consider RHF for even $N$.
\begin{equation}
\begin{aligned}
\Chi_{1}(\vec{x}_{1})=\Psi_{1}(\vec{r}_{1})\alpha(\omega_{1})\qq{,}&\Chi_{2}(\vec{x}_{1})=\Psi_{1}(\vec{r}_{1})\beta(\omega_{1})\\
\Chi_{3}(\vec{x}_{1})=\Psi_{2}(\vec{r}_{1})\alpha(\omega_{1})\qq{,}&\Chi_{4}(\vec{x}_{1})=\Psi_{2}(\vec{r}_{1})\beta(\omega_{1})\\
& \vdots\\
\end{aligned}
\end{equation}
\begin{align}
\vb{F}(\vec{x}_{1})&=\vb{h}(1)+\sum_{m=1}^{N}\qty(\vb{J}_{m}(1)-\vb{K}_{m}(1))\\
\vb{F}(\vec{x}_{1})\Chi_{n}(\vec{x}_{1})&=\varepsilon_{n}\Chi_{n}(\vec{x}_{1})
\end{align}
After integrating over all spin parts
\begin{equation}
\vb{F}(\vec{r}_{1})\Psi_{n}(\vec{r}_{1})=\varepsilon_{n}\Psi_{n}(\vec{r}_{1})
\end{equation}
with
\begin{equation}
\vb{F}(\vec{r}_{1})=\vb{h}(\vec{r}_{1})+\sum_{m=1}^{N/2}\qty(2\tikzmarknode{J}{\vb{J}}_{m}(\vec{r}_{1})-\tikzmarknode{K}{\vb{K}}_{m}(\vec{r}_{1}))
\end{equation}
\begin{center}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (J.south) -- ++ (0.2,-0.4) node[below right,align=center] {since $\int\alpha^{*}(\omega_{1})\alpha(\omega_{1})\dd{\omega_{1}}=\int\beta^{*}(\omega_{1})\beta(\omega_{1})\dd{\omega_{1}}=1$};
	\draw[red,<-,shorten <=2mm] (K.north) -- ++ (0.6,0.5) node[right,text width=7cm,align=center,yshift=0.2cm] {half vanish since $\int\alpha^{*}(\omega_{1})\beta(\omega_{1})\dd{\omega_{1}}=\int\beta^{*}(\omega_{1})\alpha(\omega_{1})\dd{\omega_{1}}=0$};
\end{tikzpicture}
\end{center}
One then obtains $\frac{N}{2}$ orbitals each containing a pair of electrons with opposite spin.

\subsection{Roothaan Equation}
To implement a Hartree-Fock solver, one must choose a basis set $\{\phi_{j}(\vec{r}_{1})\}$. Ideally, this should be a complete basis. In practice, one must choose a limited basis set with $K$ functions ($j=1,\cdots,K$). In this basis, $\Psi_{n}(\vec{r}_{1})$ is represented as
\begin{equation}
\Psi_{n}(\vec{r}_{1})=\sum_{j=1}^{K}c_{jn}\phi_{j}(\vec{r}_{1})
\end{equation}
The Hartree-Fock equation becomes
\begin{equation}
\vb{F}(\vec{r}_{1})\qty[\sum_{j=1}^{K}c_{jn}\phi_{j}(\vec{r}_{1})]=\varepsilon_{n}\qty[\sum_{j=1}^{K}c_{jn}\phi_{j}(\vec{r}_{1})]
\end{equation}
Multiplying by $\phi_{i}^{*}(\vec{r}_{1})$ and integrating
\begin{equation}
\begin{aligned}
\int\phi_{i}^{*}(\vec{r}_{1})\vb{F}(\vec{r}_{1})\qty[\sum_{j=1}^{K}c_{jn}\phi_{j}(\vec{r}_{1})]\dd{\vec{r}_{1}}&=\int\phi_{i}^{*}(\vec{r}_{1})\varepsilon_{n}\qty[\sum_{j=1}^{K}c_{jn}\phi_{j}(\vec{r}_{1})]\dd{\vec{r}_{1}}\\
\implies\sum_{j=1}^{K}c_{jn}{\color{red}\underbrace{\color{black}\int\phi_i{}^{*}(\vec{r}_{1})\vb{F}(\vec{r}_{1})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}}_{F_{ij}\,:\,\trm{Fock matrix element}}}&=\sum_{j=1}^{K}\varepsilon_{n}c_{jn}{\color{red}\underbrace{\color{black}\int\phi_{i}^{*}(\vec{r}_{1})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}}_{\mathclap{S_{ij}\,:\,\trm{Overlap matrix element}}}}
\end{aligned}
\end{equation}
where $i,\cdots,K$. In matrix form
\begin{equation}
\tikzmarknode{aa}{\vb{F}}\vb{C}=\tikzmarknode{bb}{\vb{S}}\tikzmarknode{cc}{\vb{C}}\tikzmarknode{dd}{\vb{\varepsilon}}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (aa.west) -- ++ (-0.9,0) node[left] {Fock matrix};
	\draw[red,<-,shorten <=2mm] (bb.north) -- ++ (0.5,0.3) node[right] {overlap matrix};
	\draw[red,<-,shorten <=1mm] (cc.south) -- ++ (0,-0.5) node[below] {coefficient matrix};
	\draw[red,<-,shorten <=1mm] (dd.east) -- ++ (0.5,0) node[right] {eigenvalue matrix};
\end{tikzpicture}
\begin{equation}
\mqty[F_{11} & \ldots & F_{1K}\\ \vdots & \ddots & \vdots \\ F_{K1} & \cdots & F_{KK}]\mqty[c_{11} & \ldots & c_{1K}\\ \vdots & \ddots & \vdots \\ c_{K1} & \cdots & c_{KK}]=\mqty[S_{11} & \ldots & S_{1K}\\ \vdots & \ddots & \vdots \\ S_{K1} & \cdots & S_{KK}]\mqty[c_{11} & \ldots & c_{1K}\\ \vdots & \ddots & \vdots \\ c_{K1} & \cdots & c_{KK}]\mqty[\varepsilon_{1} & \ldots & 0\\ \vdots & \ddots & \vdots \\ 0 & \ldots & \epsilon_{K}]
\end{equation}
Note that this method only gives $K$ solutions, namely
\begin{equation}
\begin{aligned}
\Psi_{1}(\vec{r}_{1})&=\sum_{j=1}^{K}c_{j1}\phi_{j}(\vec{r}_{1})\\
\Psi_{2}(\vec{r}_{1})&=\sum_{j=1}^{K}c_{j2}\phi_{j}(\vec{r}_{1})\\
&\vdots\\
\Psi_{K}(\vec{r}_{1})&=\sum_{j=1}^{K}c_{jK}\phi_{j}(\vec{r}_{1})\\
\end{aligned}
\end{equation}
Calculating the Fock matrix
\begin{equation}
\begin{aligned}
F_{ij}&=\int\phi_{i}^{*}(\vec{r}_{1})\qty[\vb{h}(\vec{r}_{1})+\sum_{m=1}^{N/2}\qty(2\vb{J}_{m}(\vec{r}_{1})-\vb{K}_{m}(\vec{r}_{1}))]\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}\\
&=\int\phi_{i}^{*}(\vec{r}_{1})\vb{h}(\vec{r}_{1})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}+\sum_{m=2}^{N/2}2\bigg[\int\phi_{i}^{*}(\vec{r}_{1})\Psi_{m}^{*}(\vec{r}_{2})\frac{1}{r_{12}}\Psi_{m}(\vec{r}_{2})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}\dd{\vec{r}_{2}}\\
&\quad-\frac{1}{2}\int\phi_{i}^{*}(\vec{r}_{1})\Psi_{m}^{*}(\vec{r}_{2})\frac{1}{r_{12}}\Psi_{m}(\vec{r}_{1})\phi_{j}(\vec{r}_{2})\dd{\vec{r}_{1}}\dd{\vec{r}_{2}}\bigg]\\
&=\int\phi_{i}^{*}(\vec{r}_{1})\vb{h}(\vec{r}_{1})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}+\sum_{m=1}^{N/2}2\Bigg[\int\phi_{i}^{*}(\vec{r}_{1})\sum_{\ell=1}^{K}c_{\ell m}^{*}\phi_{\ell}^{*}(\vec{r}_{2})\frac{1}{r_{12}}\sum_{q=1}^{K}c_{qm}\phi_{q}(\vec{r}_{2})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}\dd{\vec{r}_{2}}\\
&\quad-\frac{1}{2}\int\phi_{i}^{*}(\vec{r}_{1})\sum_{\ell=1}^{K}c_{\ell m}^{*}\phi_{\ell}^{*}(\vec{r}_{2})\frac{1}{r_{12}}\sum_{q=1}^{K}c_{qm}\phi_{q}(\vec{r}_{1})\phi_{j}(\vec{r}_{2})\dd{\vec{r}_{1}}\dd{\vec{r}_{2}}\Bigg]\\
&={\color{red}\underbrace{\color{black}\int\phi_{i}^{*}(\vec{r}_{1})\vb{h}(\vec{r}_{1})\phi_{j}(\vec{r}_{1})\dd{\vec{r}_{1}}}_{h_{ij}}}+\sum_{\ell=1}^{K}\sum_{q=1}^{K}{\color{red}\underbrace{\color{black}2\sum_{m=1}^{N/2}c_{\ell m}^{*}c_{qm}}_{P_{q\ell}}}\bigg[\int\phi_{i}^{*}(\vec{r}_{1})\phi_{j}(\vec{r}_{1})\frac{1}{r_{12}}\phi_{\ell}^{*}(\vec{r}_{2})\phi_{q}(\vec{r}_{2})\dd{\vec{r}_{1}}\dd{\vec{r}_{2}}\\
&\quad-\frac{1}{2}\int\phi_{i}^{*}(\vec{r}_{1})\phi_{q}(\vec{r}_{1})\frac{1}{r_{12}}\phi_{\ell}^{*}(\vec{r}_{2})\phi_{j}(\vec{r}_{2})\dd{\vec{r}_{1}}\dd{\vec{r}_{2}}\bigg]\\
&=h_{ij}+\sum_{\ell=1}^{K}\sum_{q=1}^{K}P_{q\ell}\qty([ij|\ell q]-\frac{1}{2}[iq|\ell j])
\end{aligned}
\end{equation}
The procedure for the self-consistent field (SCF) method thus becomes
\begin{enumerate}
\item Choose a basis set $\{\phi_{j}\}$
\item Calculate $S_{ij}$ and $h_{ij}$
\item Construct a guess for $c_{ij}$
\item Calculate \tikzmarknode{AA}{$P_{q\ell}$}
\item Calculate $F_{ij}$
\item Solve $\vb{F}\vb{C}=\vb{S}\vb{C}\vb{\varepsilon}$
\item Check \tikzmarknode{BB}{convergence}
\end{enumerate}
\begin{tikzpicture}[remember picture, overlay]
	\draw[->,shorten <=1mm, shorten >=1mm] (BB.east) -- ++ (1,0) -- node[right] {NO} ++(0,2.541) -- (AA.east);
	\draw[->,shorten <=1mm, shorten >=1mm] (BB.east) -- node[above] {YES} ++ (5,0) node[right] {Done};
\end{tikzpicture}

\newpage
Note that one does not need to recalculate $h_{ij}$, $S_{ij}$, $[ij|\ell q]$, and $[iq|\ell j]$ in each iteration. Moreover, note that $i$, $j$, $\ell$, and $q$ go from 1 to $K$. Thus, this form of the Hartree-Fock equation scales to the fourth power of the number of basis functions.

\subsection{Density Matrix and Mulliken Charge Population}
Let us now regard the matrix $P$. Note that if $N$ is the total number of electrons in the system and $\rho(\vec{r})$ is the electron density, then
\begin{equation}
N=\int\rho(\vec{r})\dd{\vec{r}}
\end{equation}
In terms of the 1-electron orbitals, one may say
\begin{equation}
\rho(\vec{r})=\sum_{m=1}^{N/2}2\abs{\Psi_{m}(\vec{r})}^{2}\qq{(for RHF)}
\end{equation}
Thus
\begin{equation}
\begin{aligned}
N&=\int\sum_{n=1}^{N/2}2\abs{\Psi_{n}(\vec{r})}^{2}\dd{\vec{r}}\\
&=\int\sum_{n=1}^{N/2}2\sum_{\ell=1}^{K}c_{\ell n}^{*}\phi_{\ell}^{*}(\vec{r})\sum_{q=1}^{K}c_{qn}\phi_{q}(\vec{r})\dd{\vec{r}}\\
&=\sum_{\ell=1}^{K}\sum_{q=1}^{K}{\color{red}\underbrace{\color{black}\sum_{n=1}^{N/2}2c_{\ell n}^{*}c_{qn}}_{P_{ql}}}\,{\color{red}\underbrace{\vphantom{\sum_{n=1}^{N/2}}\color{black}\int\phi_{\ell}^{*}(\vec{r})\phi_{q}(\vec{r})\dd{\vec{r}}}_{S_{\ell q}}}\\
&=\sum_{\ell=1}^{K}\sum_{q=1}^{K}P_{q\ell}S_{\ell q}\\
&=\sum_{q=1}^{K}\qty(\vb{P}\vb{S})_{qq}\\
&=\Tr(\vb{PS})
\end{aligned}
\end{equation}
The object $(\vb{PS})_{qq}$ can be associated with the number of electrons (which may be a fractional number) corresponding with basis function labeled by $q$. This is called \ul{Mullikan population}. Note that $P$ is also a density matrix.

\subsection{Basis Functions}
A given solution of the problem $\Psi_{n}(\vec{r})$ is expanded over $K$ basis functions.
\begin{equation}
\Psi_{n}(\vec{r})=\sum_{j=1}^{K}c_{jn}\phi_{j}(\vec{r})
\end{equation}
If the basis set is infinitely large, then the choice of basis should have no bearing on $\Psi_{n}(\vec{r})$. However, in practice, one wants a small basis set that is as ``complete" as possible. In the context of molecules, one can think of molecular orbitals as being built up from combinations of atomic orbitals. As such, it is convenient to choose basis functions that resemble atomic orbitals (1s, 2s, 2p, etc.) centred around the different nuclei.\\

In obtaining a small basis set, the Slater type orbitals have been found to work well. The equations that describe these orbitals are
\begin{equation}
e^{-\xi\abs*{\vec{r}-\vec{R}_{A}}}
\end{equation}
where $\vec{R}_{A}$ is the location of nucleus $A$.\\

For the purpose of computational efficiency, the Gaussian type orbitals simplify the integrals shown earlier in the Roothaan equation and are described by
\begin{equation}
\begin{aligned}
g_{\trm{s}j}(\vec{r})&\equiv e^{-\alpha_{j}\abs*{\vec{r}-\vec{R}_{A}}^{2}} \qq{\color{red}(s-type Gaussian)}\\
g_{\trm{p}j}(\vec{r})&\equiv xe^{-\alpha_{j}\abs*{\vec{r}-\vec{R}_{A}}^{2}} \qq{\color{red}(p-type Gaussian along $x$)}\\
g_{\trm{d}j}(\vec{r})&\equiv xye^{-\alpha_{j}\abs*{\vec{r}-\vec{R}_{A}}^{2}} \qq{\color{red}(d-type Gaussian along $xy$)}\\
\end{aligned}
\end{equation}
The above are called \ul{primitive Gaussians}.\\

To obtain the best features of both orbitals, one introduces \ul{contracted Gaussians}. They are a weighted sum of a number of primitive Gaussians
\begin{equation}
\sum_{j}A_{j}g_{j}(\vec{r})
\end{equation}
$A_{j}$ and $\alpha_{j}$ are typically determined by running Hartree-Fock on individual atoms in a molecule and matching these variables as closely to the solution given.\\

Note that these are not the only basis functions one can use. It may be desirable for the basis functions to have the same properties as the system being studied. For example, crystals have translational symmetry and long-range distribution. Thus, one could use plane-wave basis functions instead.

\newpage
\section{Post Hartree-Fock}
\subsection{Configuration Interaction}
Let us return to the many-electron Schr\"{o}dinger equation.
\begin{equation}
\tikzmarknode{aa}{\vb{H}}\Chi=\tikzmarknode{bb}{E}\tikzmarknode{cc}{\Chi}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (aa.west) -- ++(-0.5,0) node[left,text width=2.5cm,align=center] {many-electron Hamiltonian};
	\draw[red,<-,shorten <=1mm] (bb.south) -- ++(0,-0.5) node[below] {energy};
	\draw[red,<-,shorten <=1mm] (cc.east) -- ++(0.5,0) node[right,text width=2.5cm,align=center] {many-electron wavefunction};
\end{tikzpicture}

In Hartree-Fock, $\Chi$ was assumed to take the form of a Slater determinant. Let us not make this approximation. To solve this problem, we need a basis set to be able to expand $\Chi(\vec{x}_{1},\vec{x}_{2},\cdots,\vec{x}_{N})$ over.\\

Let us recall the Hartree-Fock equation.
\begin{equation}
\vb{F}\Chi_{n}(\vec{x}_{1})=\varepsilon_{n}\Chi_{n}(\vec{x}_{1})\qq{,}n=1,\cdots,\infty
\end{equation}
Since $\vb{F}$ is Hermitian, the eigenfunctions form a complete basis set. If one takes an arbitrary function $\Psi(\vec{x}_{1})$ of one electron, it can be expanded as
\begin{equation}
\Psi(\vec{x}_{1})=\sum_{i=1}^{\infty}a_{i}\Chi_{i}(\vec{x}_{1})
\end{equation}
Now consider an arbitrary two-electron function $\Psi(\vec{x}_{1},\vec{x}_{2})$. If $\vec{x}_{2}$ is held fixed, the function depends on $\vec{x}_{1}$ only and can be expanded as done above. For a different value of fixed $\vec{x}_{2}$, the expansion above can still be done, but the values of the coefficients $a_{i}$ must change. Thus
\begin{equation}
\Psi(\vec{x}_{1},\vec{x}_{2})=\sum_{i=1}^{\infty}a_{i}(\vec{x}_{2})\Chi_{i}(\vec{x}_{1})
\end{equation}
However, if $a_{i}$ is a function of $\vec{x}_{2}$, the coefficient itself can be expanded over the same basis set. Thus
\begin{equation}
\begin{aligned}
a_{i}(\vec{x}_{2})=\sum_{j=1}^{\infty}b_{ji}\Chi_{j}(\vec{x}_{2})\\
\implies \Psi(\vec{x}_{1},\vec{x}_{2})&=\sum_{i=1}^{\infty}\sum_{j=1}^{\infty}b_{ji}\Chi_{j}(\vec{x}_{2})\Chi_{i}(\vec{x}_{1})
\end{aligned}
\end{equation}
However, $\Psi(\vec{x}_{1},\vec{x}_{2})$ should be anti-symmetric.
\begin{equation}
\Psi(\vec{x}_{1},\vec{x}_{2})=-\Psi(\vec{x}_{2},\vec{x}_{1})
\end{equation}
which leads to the constraint
\begin{equation}
b_{ji}=-b_{ij}
\end{equation}
Thus
\begin{equation}
\Psi(\vec{x}_{1},\vec{x}_{2})=\sum_{i,j=1}^{\infty}b_{ji}\qty[\Chi_{i}(\vec{x}_{1})\Chi_{j}(\vec{x}_{2})-\Chi_{i}(\vec{x}_{2})\Chi_{j}(\vec{x}_{1})]
\end{equation}
with constants being absorbed into $b_{ji}$. Thus, an arbitrary two-electron wavefunction can be expanded over two-electron Slater determinants that are themselves constructed from the one-electron basis set found from Hartree-Fock. These sets of two-electron Slater determinants are themselves a complete basis set for all anti-symmetric two-electron wavefunctions. This argument generalizes to $N$-electron wavefunctions. Note that the one-electron basis set needs not to be obtained from Hartree-Fock for this argument to apply.\\

Thus, for configuration interaction (CI), one first solves Hartree-Fock with $K$ basis functions. One then constructs all possible $N$-electron Slater determinants out of the Hartree-Fock solutions. There are $(^{K}_{N})$ of these Slater determinants. One then writes the original Schr\"{o}dinger equation in matrix form using these Slater determinants as basis functions and solves for the eigenvalues and eigenfunctions. As $K$ approaches infinity, these solutions become exact.
\begin{center}
\begin{tikzpicture}
	\foreach \y in {0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5} {
		\draw (0,\y) -- (3,\y);
	}
	\node[above] at (1.5,5) {HF};
	\draw[decorate,decoration={brace,amplitude=10pt}] (-0.5,0) -- (-0.5,5) node[left,midway,xshift=-0.5cm] {$K$};
	\draw[decorate,decoration={brace,amplitude=10pt,mirror}] (3.5,0) -- (3.5,2) node[right,midway,xshift=0.5cm] {$N$};
	\node[text width=5cm] at (7,4) {$(^{K}_{N})$ Slater determinants serve as CI basis set};
\end{tikzpicture}
\end{center}
In practice, CI becomes extremely computationally intensive. However, there are variants one can use to truncate this set. For instance, using only the singly excited determinants or using only the singly and doubly excited determinants (CISD) drastically reduces the computational resources required.
\begin{center}
\begin{tikzpicture}
	\draw[->] (-0.5,0) -- (7,0) node[right] {$K$};
	\draw[->] (0,-0.5) -- (0,5) node[above] {$(^{K}_{N})$};
	\draw[red,->] (-0.5,0.5) -- node[left,text width=1cm,align=center] {better CI} (-0.5,4.5);
	\draw[red,->] (0.5,-0.5) -- node[below] {better HF} (6.5,-0.5);
	\draw[red,->] (0,0) -- (7,5) node[right,text width=7cm,align=center] {Exact solution (non-relativistic + Born-Oppenheimer)};
	\draw[red,dashed,thin] (0,2) -- (5,2) -- (5,0);
	\filldraw[red] (5,2) circle (2pt) node[right,xshift=0.2cm] {Solution found by limiting $K$ and $(^{K}_{N})$};
\end{tikzpicture}
\end{center}
One can define the correlation energy as
\begin{equation}
E_{\trm{correlation}}=E_{\trm{exact}}-E_{\trm{HF}}
\end{equation}

\subsection{M{\o}ller-Plesset Perturbation Theory}
Let us write the many-body Hamiltonian as
\begin{equation}
\vb{H}=\tikzmarknode{aa}{\vb{H}_{0}}+\tikzmarknode{bb}{\lambda\vb{V}}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-] (aa.south) -- ++(0,-0.3) node[below] {reference Hamiltonian};
	\draw[red,<-] (bb.east) -- ++(0.5,0) node[right] {perturbation};
\end{tikzpicture}

In M{\o}ller-Plesset perturbation theory (MPPT), $\vb{H}_{0}$ is the Hartree-Fock Hamiltonian (not the Fock operator). It is given by
\begin{equation}
\vb{H}_{0}=\sum_{i=1}^{N}\vb{F}(i)
\end{equation}
The energy for a given state will be written as
\begin{equation}
\begin{aligned}
E_{i}&=\sum_{j=0}^{\infty}\lambda^{j}E_{i}^{(j)}\\
&=E_{i}^{(0)}+\lambda E_{i}^{(1)}+\lambda^{2}E_{i}^{(2)}+\ldots
\end{aligned}
\end{equation}
The many-body wavefunction will be written as
\begin{equation}
\begin{aligned}
\ket{\Chi_{i}}&=\sum_{j=0}^{\infty}\lambda^{j}\ket{\Chi_{i}^{(j)}}\\
&=\ket{\Chi_{i}^{(0)}}+\lambda\ket{\Chi_{i}^{(1)}}+\lambda^{2}\ket{\Chi_{i}^{(2)}}+\ldots
\end{aligned}
\end{equation}
Substituting into the many-electron Schr\"{o}dinger equation
\begin{equation}
\qty(\vb{H}_{0}+\lambda\vb{V})\qty(\ket{\Chi_{i}^{(0)}}+\lambda\ket{\Chi_{i}^{(1)}}+\ldots)=\qty(E_{i}^{(0)}+\lambda E_{i}^{(1)}+\ldots)\qty(\ket{\Chi_{i}^{(0)}}+\lambda\ket{\Chi_{i}^{(1)}}+\ldots)
\end{equation}
Matching orders of $\lambda$
\begin{equation}
\begin{aligned}
\vb{H}_{0}\ket{\Chi_{i}^{(0)}}&=E_{i}^{(0)}\ket{\Chi_{i}^{(0)}}\qq{(Zeroth order)}\\
\vb{H}_{0}\ket{\Chi_{i}^{(1)}}&+\vb{V}\ket{\Chi_{i}^{(0)}}=E_{i}^{(0)}\ket{\Chi_{i}^{(1)}}+E_{i}^{(1)}\ket{\Chi_{i}^{(0)}}\qq{(First order)}\\
\vb{H}_{0}\ket{\Chi_{i}^{(2)}}&+\vb{V}\ket{\Chi_{i}^{(1)}}=E_{i}^{(0)}\ket{\Chi_{i}^{(2)}}+E_{i}^{(1)}\ket{\Chi_{i}^{(1)}}+E_{i}^{(2)}\ket{\Chi_{i}^{(0)}}\qq{(Second order)}\\
&\qquad\qquad\vdots
\end{aligned}
\end{equation}
One can introduce normalization conditions
\begin{equation}
\ip{\Chi_{i}^{(0)}}{\Chi_{i}^{(0)}}=1\qq{\color{red}(can always be done)}
\end{equation}
Additionally, one can then choose
\begin{equation}
\ip{\Chi_{i}^{(0)}}{\Chi_{i}}=1\qq{\color{red}(chosen to help find $\ket{\Chi_{i}}$)}
\end{equation}
Thus
\begin{equation}
\ip{\Chi_{i}^{(0)}}{\Chi_{i}^{(1)}}=\ip{\Chi_{i}^{(0)}}{\Chi_{i}^{(2)}}=\ldots=0
\end{equation}
Multiplying on the left by $\bra{\Chi_{i}^{(0)}}$ for the first order equation
\begin{equation}
\begin{aligned}
\cancelto{\mathrlap{0\trm{, since }\vb{H}\ket{\Chi_{i}^{(0)}}=E_{i}^{(0)}\ket{\Chi_{i}^{(0)}}}}{\mel{\Chi_{i}^{(0)}}{\vb{H}}{\Chi_{i}^{(1)}}}&+\mel{\Chi_{i}^{(0)}}{\vb{V}}{\Chi_{i}^{(0)}}\\
&=\cancelto{0}{\mel{\Chi_{i}^{(0)}}{E_{i}^{(0)}}{\Chi_{i}^{(1)}}}+\mel{\Chi_{i}^{(0)}}{E_{i}^{(1)}}{\Chi_{i}^{(0)}}\\
\implies E_{I}^{(1)}&=\mel{\Chi_{i}^{(0)}}{\vb{V}}{\Chi_{i}^{(0)}}
\end{aligned}
\end{equation}
Solving for $\ket{\Chi_{i}^{(1)}}$
\begin{equation}
\qty(E_{i}^{(0)}-\vb{H}_{0})\ket{\Chi_{i}^{(1)}}=\qty(\vb{V}-E_{i}^{(1)})\ket{\Chi_{i}^{(0)}}
\end{equation}
Since $\qty{\ket{\Chi_{i}^{(0)}}}$ forms a complete basis set, one can write
\begin{equation}
\begin{aligned}
\ket{\Chi_{i}^{(1)}}&=\sum_{j}c_{ji}\ket{\Chi_{i}^{(0)}}\\
c_{ji}&=\ip{\Chi_{j}^{(0)}}{\Chi_{i}^{(1)}}
\end{aligned}
\end{equation}
Thus
\begin{equation}
\begin{aligned}
\mel{\Chi_{j}^{(0)}}{\qty(E_{i}^{(0)}-\vb{H}_{0})}{\Chi_{i}^{(1)}}&=\mel{\Chi_{j}^{(0)}}{\qty(\vb{V}-E_{i}^{(1)})}{\Chi_{i}^{(0)}}\\
\implies E_{i}^{(0)}\ip{\Chi_{j}^{(0)}}{\Chi_{i}^{(1)}}-E_{j}^{(0)}\ip{\Chi_{j}^{(0)}}{\Chi_{i}^{(1)}}&=\mel{\Chi_{j}^{(0)}}{\vb{V}}{\Chi_{i}^{(0)}}-E_{i}^{(1)}\ip{\Chi_{j}^{(0)}}{\Chi_{i}^{(0)}}
\end{aligned}
\end{equation}
For $i\neq j$
\begin{equation}
\begin{aligned}
c_{ji}&=\frac{\mel{\Chi_{j}^{(0)}}{\vb{V}}{\Chi_{i}^{(0)}}}{E_{i}^{(0)}-E_{j}^{(0)}}\\
\implies\ket{\Chi_{i}^{(1)}}&=\sum_{j\neq i}\frac{\mel{\Chi_{j}^{(0)}}{\vb{V}}{\Chi_{i}^{(0)}}}{E_{i}^{(0)}-E_{j}^{(0)}}\ket{\Chi_{j}^{(0)}}
\end{aligned}
\end{equation}

\newpage
\section{Density Functional Theory}
\subsection{Functionals and Functional Differentiation}
A \ul{functional} maps a function to a numeric value. In the case of density functional theory, the electron density gets mapped to different values by various functionals.
\[
n(\vec{r})\rightarrow F[n(\vec{r})]
\]
For a difference in function $n(\vec{r})$, how does the functional $F[n(\vec{r})]$ change? This is given by
\[
\fdv{F[n(\vec{r})]}{n(\vec{r})}\qq{\color{red}(functional differentation)}
\]
where
\begin{equation}
\int\fdv{F[n(\vec{r})]}{n(\vec{r})}g(\vec{r})\dd{\vec{r}}=\lim_{\varepsilon\rightarrow0}\frac{1}{\varepsilon}\big[F[n(\vec{r})+\varepsilon g(\vec{r})]-F[n(\vec{r})]\big]
\end{equation}

\begin{center}
\begin{tikzpicture}
	\draw[<->] (0,-1) -- (0,4) node[above] {$n(\vec{r})$};
	\draw[<->] (-4,0) -- (4,0) node[right] {$\vec{r}$};
	\draw[blue] plot [smooth] coordinates {(-4,1.8) (-3.5,2.1) (-3,2.3) (-2.2,2.7) (-1.5,1.8) (-0.2,1.2) (1.5,1.5) (3.2,2.9) (4,2.5)};
	\draw[red,dashed] plot [smooth] coordinates {(-4,1.9) (-3.5,2.2) (-3,2.35) (-2.2,2.6) (-1.5,1.9) (-0.2,1.25) (1.5,1.6) (3.2,3.05) (4,2.6)};
	\draw[->] (3.5,2.5) -- (3.5,2.8);
	\draw[<-] (3.5,3.1) -- (3.5,3.4) node[right] {$\var{n(\vec{r})}$};
	\node[blue,below left] at (-4,1.8) {$n(\vec{r})$};
	\node[red,above left] at (-4,1.9) {$n(\vec{r})+\var{n(\vec{r})}$};
\end{tikzpicture}
\end{center}

\aside{Ex}{Consider
\begin{equation}
F[n(\vec{r})]=\int v(\vec{r})n(\vec{r})\dd{\vec{r}}
\end{equation}
By definition
\begin{equation}
\begin{aligned}
\int\fdv{F[n(\vec{r})]}{n(\vec{r})}g(\vec{r})\dd{\vec{r}}&=\lim_{\varepsilon\rightarrow0}\frac{1}{\varepsilon}\qty[\int v(\vec{r})[n(\vec{r})+\varepsilon g(\vec{r})]\dd{\vec{r}}-\int v(\vec{r})n(\vec{r})\dd{\vec{r}}]\\
&=\lim_{\varepsilon\rightarrow0}\frac{1}{\varepsilon}\int v(\vec{r})\varepsilon g(\vec{r})\dd{\vec{r}}\\
&=\int v(\vec{r})g(\vec{r})\dd{\vec{r}}
\end{aligned}
\end{equation}
Thus, since $g(\vec{r})$ is arbitrary
\begin{equation}
\fdv{F[n(\vec{r})]}{n(\vec{r})}=v(\vec{r})
\end{equation}
}

\subsection{Density Functional Theory}
The original many-electron problem had the form of
\begin{equation}
\vb{H}\ket{\Chi_{i}}=E_{i}\ket{\Chi_{i}}\qq{,}i=1,\cdots,\infty\qq{,}\ket{\Chi_{i}}\equiv\Chi_{i}(\vec{x}_{1},\cdots,\vec{x}_{N})
\end{equation}
Density functional theory (DFT) transforms this problem into
\begin{equation}
\vb{H}_{\trm{eff}}\Psi_{i}(\vec{r}_{1})=\varepsilon_{i}\Psi_{i}(\vec{r}_{1})
\end{equation}
The history of density functional theory can be traced back to two seminal papers: Hohenberg and Kohn (1964) and Kohn and Sham (1965). In essence, it recasts the problem from regarding the many-electron wavefunction to regarding the electron density $n(\vec{r})$.

\subsection{Hohenberg-Kohn Theorems}
Recall the many-electron Hamiltonian is
\begin{equation}
\vb{H}=\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}+\sum_{i=1}^{N}\sum_{j\neq i}^{N}\frac{1}{r_{ij}}+{\color{red}\underbrace{\color{black}\sum_{i=1}^{N}{\color{red}\overbrace{\color{black}\sum_{A=1}^{M}-\frac{Z_{A}}{r_{iA}}}^{\mathclap{\trm{external potential $v(\vec{r}_{i})$}}}}}_{\mathclap{\substack{\trm{total external potential acting}\\ \trm{on the electronic system}}}}}
\end{equation}
\aside[0]{Theorem 1}{The external potential $v(\vec{r})$ acting as a fully-interacting system of $N$ electrons in a ground state is determined, within an additive constant, by the electron density $n(\vec{r})$.
}
\newpage
\aside{Proof}{Imagine two external potentials, $v(\vec{r})$ and $v^{\prime}(\vec{r})$, which differ by more than an additive constant, which lead to the same electron density $n(\vec{r})$ in the ground state.\\

Let $\vb{H}$ be the Hamiltonian associated with $v(\vec{r})$, with ground state $\ket{\Chi_{0}}$ and ground state energy $E_{0}$. Let $\vb{H}^{\prime}$ be the Hamiltonian associated with $v^{\prime}(\vec{r})$, with ground state $\ket{\Chi_{0}^{\prime}}$ and ground state energy $E_{0}^{\prime}$.\\

By the variational principle
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}^{\prime}}{\vb{H}}{\Chi_{0}^{\prime}}&>E_{0}\\
\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}&>E_{0}^{\prime}
\end{aligned}
\end{equation}
The terms evaluated explicitly are
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}^{\prime}}{\vb{H}}{\Chi_{0}^{\prime}}&=\int\Chi_{0}^{\prime *}(\vec{x}_{1},\cdots,\vec{x}_{N})\qty(\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2})\Chi_{0}^{\prime}(\vec{x}_{1},\cdots,\vec{x}_{N})\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}\\
&\quad+\int\Chi_{0}^{\prime *}(\vec{x}_{1},\cdots,\vec{x}_{N})\qty(\sum_{i=1}^{N}\sum_{j\neq i}^{N}\frac{1}{r_{ij}})\Chi_{0}^{\prime}(\vec{x}_{1},\cdots,\vec{x}_{N})\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}\\
&\quad+\int\Chi_{0}^{\prime *}(\vec{x}_{1},\cdots,\vec{x}_{N})\qty(\sum_{i=1}^{N}v(\vec{r}_{i}))\Chi_{0}^{\prime}(\vec{x}_{1},\cdots,\vec{x}_{N})\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}\\
&=\trm{Kinetic term} + \trm{e$^{-}$-e$^{-}$ interaction term}\\
&\quad+\int\Chi_{0}^{\prime *}(\vec{x}_{1},\cdots,\vec{x}_{N})\qty(\sum_{i=1}^{N}\int v(\vec{r})\delta(\vec{r}_{i}-\vec{r})\dd{\vec{r}})\Chi_{0}^{\prime}(\vec{x}_{1},\cdots,\vec{x}_{N})\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}
\end{aligned}
\end{equation}
The third term becomes
\begin{equation}
\int v(\vec{r})\dd{\vec{r}}{\color{red}\overbrace{\color{black}\int\Chi_{0}^{\prime *}(\vec{x}_{1},\cdots,\vec{x}_{N}){\color{red}\underbrace{\color{black}\qty(\sum_{i=1}^{N}\delta(\vec{r}_{i}-\vec{r}))}_{\mathclap{\trm{density operator}}}}\Chi_{0}^{\prime}(\vec{x}_{1},\cdots,\vec{x}_{N})\dd{\vec{x}_{1}}\ldots\dd{\vec{x}_{N}}}^{n(\vec{r})}}
\end{equation}
Thus
\begin{equation}
\mel{\Chi_{0}^{\prime}}{\vb{H}}{\Chi_{0}^{\prime}}=\trm{Kinetic term} + \trm{e$^{-}$-e$^{-}$ interaction term}+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}
\end{equation}
By a similar argument
\begin{equation}
\mel{\Chi_{0}}{\vb{H}^{\prime}}{\Chi_{0}}=\trm{Kinetic term} + \trm{e$^{-}$-e$^{-}$ interaction term}+\int v^{\prime}(\vec{r})n(\vec{r})\dd{\vec{r}}
\end{equation}
Note that
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}^{\prime}}{\vb{H}}{\Chi_{0}^{\prime}}&=\mel{\Chi_{0}^{\prime}}{\qty(\vb{H}-\vb{H}^{\prime})}{\Chi_{0}^{\prime}}+\mel{\Chi_{0}^{\prime}}{\vb{H}^{\prime}}{\Chi_{0}^{\prime}}\\
&=\int\qty(v(\vec{r})-v^{\prime}(\vec{r}))n(\vec{r})\dd{\vec{r}}+E_{0}^{\prime}\\
\implies E_{0}&< \int\qty(v(\vec{r})-v^{\prime}(\vec{r}))n(\vec{r})\dd{\vec{r}}+E_{0}^{\prime}
\end{aligned}
\end{equation}
Similarly
\begin{equation}
\begin{aligned}
\mel{\Chi_{0}}{\vb{H}^{\prime}}{\Chi_{0}}&=\mel{\Chi_{0}}{\qty(\vb{H}^{\prime}-\vb{H})}{\Chi_{0}}+\mel{\Chi_{0}}{\vb{H}}{\Chi_{0}}\\
&=\int\qty(v^{\prime}(\vec{r})-v(\vec{r}))n(\vec{r})\dd{\vec{r}}+E_{0}\\
\implies E_{0}^{\prime}&< \int\qty(v^{\prime}(\vec{r})-v(\vec{r}))n(\vec{r})\dd{\vec{r}}+E_{0}
\end{aligned}
\end{equation}
Thus, adding the two inequalities together
\begin{equation}
E_{0}+E_{0}^{\prime}<E_{0}+E_{0}^{\prime}
\end{equation}
which is a contradiction.
}
Thus, $n(\vec{r})$ uniquely determines $v(\vec{r})$, up to an additive constant, which will give the Hamiltonian $\vb{H}$. This subsequently gives everything else. Therefore, one can write the various energies as a functional of the electron density $n(\vec{r})$.
\begin{equation}
E_{0}[n(\vec{r})]={\color{red}\underbrace{\color{black}T[n(\vec{r})]+U_{\trm{ee}}[n(\vec{r})]}_{\mathclap{F_{\trm{HK}}[n(\vec{r})]\,:\,\trm{Hohenberg-Kohn functional}}}}+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}
\end{equation}
Thus, one can see that the problem involving $3N$ spatial coordinates has been converted into a problem involving only 3 spatial coordinates.

\aside[0]{Theorem 2}{This restates the variational principle in terms of electron density.
\begin{equation}
E_{0}[n^{\prime}(\vec{r})]>E_{0}
\end{equation}
}

\aside{Proof}{Note that $n^{\prime}(\vec{r})$ determines the Hamiltonian, which ultimately gives the state $\ket{\Chi_{0}^{\prime}}$. From the previous form of the variational principle
\begin{equation}
{\color{red}\underbrace{\color{black}\mel{\Chi_{0}^{\prime}}{\vb{H}}{\Chi_{0}^{\prime}}}_{\mathrlap{=\,F_{\trm{HK}}[n^{\prime}(\vec{r})]+\int v(\vec{r})n^{\prime}(\vec{r})\dd{\vec{r}}\,=\,E_{0}[n^{\prime}(\vec{r})]}}}>E_{0}
\end{equation}
}

\subsection{Kohn-Sham Method}
The functional describing the electron-electron interaction can be broken up into a classical Coulomb term and a non-classical term
\begin{equation}
U_{\trm{ee}}[n(\vec{r})]={\color{red}\underbrace{\color{black}\frac{1}{2}\int\frac{n(\vec{r})n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}}\dd{\vec{r}^{\prime}}}_{J[n(\vec{r})]}}+\trm{non-classical term}
\end{equation}
In this method, imagine a reference system of non-interacting electrons
\begin{equation}
\vb{H}_{\trm{ref}}=\sum_{i=1}^{N}-\frac{1}{2}\nabla_{i}^{2}+\tikzmarknode{aa}{\sum_{i=1}^{N}v_{\trm{ref}}(\vec{r}_{i})}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (aa.east) -- ++(0.5,-0.3) node[right,text width=6cm,align=center] {acts only on one electron because they are non-interacting};
\end{tikzpicture}
with $\vb{H}_{\trm{ref}}\Psi_{i}(\vec{r})=\varepsilon_{i}\Psi_{i}(\vec{r})$ and $\Psi_{i}(\vec{r})$ is some one-electron function.\\

The key feature is that the external potential of the reference system $v_{\trm{ref}}$ is chosen such that the electron density of this reference system is equal to the electron density of the actual system of interest (where the electrons are interesting). The electron density is given by
\begin{equation}
n(\vec{r})=\sum_{i=1}^{N}\Psi_{i}^{*}(\vec{r})\Psi_{i}(\vec{r})
\end{equation}
The kinetic energy of the reference system is given by
\begin{equation}
T_{\trm{ref}}[n(\vec{r})]=\sum_{i=1}^{N}\mel{\Psi_{i}}{-\frac{1}{2}\nabla_{i}^{2}}{\Psi_{i}}\tikzmarknode{aa}{\neq}\,T[n(\vec{r})]
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (aa.south) -- ++(0,-0.3) node[below] {do not assume they are the same};
\end{tikzpicture}

\newpage
For the actual system
\begin{equation}
\begin{aligned}
E_{0}[n(\vec{r})]&={\color{red}\underbrace{\color{black}T_{\trm{ref}}[n(\vec{r})]+\trm{kinetic energy missing from reference system}}_{T[n(\vec{r})]}}\\
&\quad+{\color{red}\underbrace{\color{black}J[n(\vec{r})]+\trm{non-classical term}}_{U_{\trm{ee}}[n(\vec{r})]}}+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}
\end{aligned}
\end{equation}
The sum of these two unknown terms is the \ul{exchange-correlation energy} $E_{xc}[n(\vec{r})]$.
\begin{equation}
\implies E_{0}[n(\vec{r})]=T_{\trm{ref}}[n(\vec{r})]+J[n(\vec{r})]+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}+E_{\trm{xc}}[n(\vec{r})]
\end{equation}
Since the reference system was chosen to match electron density, $n(\vec{r})$ can be calculated using the definition above using the reference $\Psi_{i}(\vec{r})$.\\

We now minimize $E_{0}[n(\vec{r})]$ subject to the constraint that
\begin{equation}
\int\Psi_{i}^{*}(\vec{r})\Psi_{j}(\vec{r})\dd{\vec{r}}=\delta_{ij}
\end{equation}
Define a Lagrange function
\begin{equation}
\begin{aligned}
\mathcal{L}[n(\vec{r})]=E_{0}[n(\vec{r})]-\sum_{i=1}^{N}\sum_{j\neq i}^{N}\varepsilon_{ij}\qty(\int\Psi_{i}^{*}(\vec{r})\Psi_{j}(\vec{r})\dd{\vec{r}}-\delta_{ij})
\end{aligned}
\end{equation}
Set $\var{\mathcal{L}}=0$ when the set $\{\Psi_{i}\}$ is changed to $\{\Psi_{i}+\var{\Psi_{i}}\}$. To first order, the variation in $n(\vec{r})$ is
\begin{equation}
\var{n(\vec{r})}=\sum_{i=1}^{N}\qty[\var{\Psi_{i}^{*}(\vec{r})}\Psi_{i}(\vec{r})+\Psi_{i}^{*}(\vec{r})\var{\Psi_{i}(\vec{r})}]
\end{equation}
For the terms in $E_{0}[n(\vec{r})]$, the variations are
\begin{equation}
\var{T_{\trm{ref}}[n(\vec{r})]}=\sum_{i=1}^{N}\int\var{\Psi_{i}^{*}(\vec{r})}\qty(-\frac{1}{2}\nabla^{2})\Psi_{i}(\vec{r})\dd{\vec{r}}+\qcc*
\end{equation}
\begin{equation}
\begin{aligned}
\var{J[n(\vec{r})]}&=\int\frac{n(\vec{r}^{\prime})\var{n(\vec{r})}}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}}\dd{\vec{r}^{\prime}}\\
&=\int\frac{n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}\qty(\sum_{i=1}^{N}\var{\Psi_{i}^{*}(\vec{r})}\Psi_{i}(\vec{r})+\trm{c.c.})\dd{\vec{r}}
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
\var{\qty(\int v(\vec{r})n(\vec{r})\dd{\vec{r}})}&=\int v(\vec{r})\var{n(\vec{r})}\dd{\vec{r}}\\
&=\int v(\vec{r})\qty(\sum_{i=1}^{N}\var{\Psi_{i}^{*}(\vec{r})}\Psi_{i}(\vec{r})+\trm{c.c.})\dd{\vec{r}}
\end{aligned}
\end{equation}
The variation in the exchange-correlation energy is
\begin{equation}
\begin{aligned}
\var{E_{\trm{xc}}[n(\vec{r})]}&=\int\fdv{E_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}\var{n(\vec{r})}\dd{\vec{r}}\\
&=\int\fdv{E_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}\qty(\sum_{i=1}^{N}\var{\Psi_{i}^{*}(\vec{r})}\Psi_{i}(\vec{r})+\trm{c.c.})\dd{\vec{r}}
\end{aligned}
\end{equation}
Thus
\begin{equation}
\begin{aligned}
\var{\mathcal{L}[n(\vec{r})]}&=\sum_{i=1}^{N}\int\dd{\vec{r}}\var{\Psi_{i}^{*}(\vec{r})}\bigg\{\qty[-\frac{1}{2}\nabla^{2}+\int\frac{n(\vec{r}^{\prime})}{\abs*{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+v(\vec{r})+\fdv{E_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}]\Psi_{i}(\vec{r})\\
&\quad\quad-\sum_{j=1}^{N}\varepsilon_{ij}\Psi_{j}(\vec{r})\bigg\}+\qcc*
\end{aligned}	
\end{equation}
For $\var{\mathcal{L}}=0$ where $\{\var{\Psi_{i}}\}$ are arbitrary
\begin{equation}
\qty[-\frac{1}{2}\nabla^{2}+\int\frac{n(\vec{r}^{\prime})}{\abs*{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+v(\vec{r})+\fdv{E_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}]\Psi_{i}(\vec{r})=\sum_{j=1}^{N}\varepsilon_{ij}\Psi_{j}(\vec{r})
\end{equation}
Without loss of generality, let us work with diagonal matrix elements $\varepsilon_{i}$. We shall also define an effective potential given by
\begin{equation}
v_{\trm{ref}}(\vec{r})=v(\vec{r})+\int\frac{n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+\fdv{E_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}
\end{equation}
Thus, we recast the above equation as
\begin{equation}
\vb{H}_{\trm{eff}}\Psi_{i}(\vec{r})=\varepsilon_{i}\Psi_{i}(\vec{r})\qq{,}i=1,\cdots,\infty
\end{equation}
where
\begin{equation}
\vb{H}_{\trm{eff}}(\vec{r})=-\frac{1}{2}\nabla^{2}+v_{\trm{eff}}(\vec{r})
\end{equation}
and
\begin{equation}
n(\vec{r})=\sum_{i=1}^{N}\Psi_{i}^{*}(\vec{r})\Psi_{i}(\vec{r})
\end{equation}
These are the \ul{Kohn-Sham equations}. Thus, the steps of the Kohn-Sham method are
\begin{enumerate}
\item Guess initial $\{\Psi_{i}\}$
\item Calculate \tikzmarknode{aa}{$n(\vec{r})$}
\item Calculate $v_{\trm{eff}}(\vec{r})$
\item Calculate $\vb{H}_{\trm{eff}}$
\item Solve $\vb{H}_{\trm{eff}}\Psi_{i}=\varepsilon_{i}\Psi_{i}$
\item Test for \tikzmarknode{bb}{convergence}
\end{enumerate}
\begin{tikzpicture}[remember picture, overlay]
	\draw[->,shorten <=1mm, shorten >=1mm] (bb.east) -- ++ (1,0) -- node[right] {NO} ++(0,3.5) -- (aa.east);
	\draw[->,shorten <=1mm, shorten >=1mm] (bb.east) -- node[above] {YES} ++ (5,0) node[right] {Done};
\end{tikzpicture}

\subsection{Total Energy and Koopmans' Theorem in DFT}
Recall the total energy functional is
\begin{equation}
E_{0}[n(\vec{r})]=T_{\trm{ref}}[n(\vec{r})]+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}+\frac{1}{2}\int\frac{n(\vec{r})n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}}\dd{\vec{r}^{\prime}}+E_{\trm{xc}}[n(\vec{r})]
\end{equation}
We shall relate $\varepsilon_{i}$ to this value. Note that
\begin{equation}
\begin{aligned}
\sum_{i=1}^{N}\varepsilon_{i}&=\sum_{i=1}^{N}\mel{\Psi_{i}}{\vb{H}_{\trm{eff}}}{\Psi_{i}}\\
&=\sum_{i=1}^{N}\mel{\Psi_{i}}{\bigg(-\frac{1}{2}\nabla_{i}^{2}+v(\vec{r})+\int\frac{n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+{\color{red}\overbrace{\color{black}\fdv{E_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}}^{\smash{V_{\trm{xc}}[n(\vec{r})]}}}\bigg)}{\Psi_{i}}\\
&=T_{\trm{ref}}[n(\vec{r})]+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}+\int\frac{n(\vec{r}^{\prime})n(\vec{r})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}\dd{\vec{r}}+E_{\trm{xc}}[n(\vec{r})]\\
&\quad+\int V_{\trm{xc}}[n(\vec{r})]n(\vec{r})\dd{\vec{r}}
\end{aligned}
\end{equation}
\begin{equation}
\implies E_{0}[n(\vec{r})]=\sum_{i=1}^{N}\varepsilon_{i}-\frac{1}{2}\int\frac{n(\vec{r}^{\prime})n(\vec{r})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}\dd{\vec{r}}+E_{\trm{xc}}[n(\vec{r})]-\int V_{\trm{xc}}[n(\vec{r})]n(\vec{r})\dd{\vec{r}}
\end{equation}
Thus
\begin{equation}
E_{0}[n(\vec{r})]\neq\sum_{i=1}^{N}\varepsilon_{i}
\end{equation}
In DFT, Koopmans' theorem states that the first ionization energy of this system is equal to the negative of the energy of the highest occupied molecular orbital. A proof of this theorem follows a similar vein of the proof done for Hartree-Fock.\\

Let us now consider the chemical potential $\mu$ using the following Lagrange function.
\begin{equation}
\mathcal{L}[n(\vec{r})]=E_{0}[n(\vec{r})]-\mu\qty(\int n(\vec{r})\dd{\vec{r}}-N)
\end{equation}
Setting $\var{\mathcal{L}}=0$
\begin{equation}
\mu=\fdv{E_{0}[n(\vec{r})]}{n(\vec{r})}=v(\vec{r})+\var{F_{\trm{HK}}[n(\vec{r})]}
\end{equation}

\subsection{Exchange Correlation Functionals}
What is $E_{\trm{xc}}[n(\vec{r})]$?\\

With local density approximation (LDA), one assumes that the exchange-correlation potential at each point in space is equal to the exchange-correlation potential of a uniform electron gas whose density is equal to the density of the actual system at that point.
\begin{equation}
E_{\trm{xc}}[n(\vec{r})]=\int\varepsilon_{\trm{xc}}[n(\vec{r})]n(\vec{r})\dd{\vec{r}}
\end{equation}
where
\begin{equation}
\varepsilon_{\trm{xc}}[n(\vec{r})]={\color{red}\underbrace{\color{black}\varepsilon_{\trm{x}}[n(\vec{r})]}_{\mathclap{\substack{\trm{exchange}\\\trm{term}}}}}+{\color{red}\underbrace{\color{black}\varepsilon_{\trm{c}}[n(\vec{r})]}_{\mathclap{\substack{\trm{correlation}\\\trm{term}}}}}
\end{equation}
One possible exchange term is the Dirac exchange.
\begin{equation}
\varepsilon_{\trm{x}}[n]=-\frac{3}{4}\qty(\frac{3}{\pi})^{\frac{1}{3}}n^{\frac{1}{3}}\qq{(for a uniform electron gas)}
\end{equation}
Another is the Slater exchange
\begin{equation}
\varepsilon_{\trm{x}}[n]=-\frac{3}{2}\tikzmarknode{aa}{\alpha}\qty(\frac{3}{\pi})^{\frac{1}{3}}n^{\frac{1}{3}}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (aa.south) -- ++(0,-0.3) node[below] {adjustable parameter, often around 0.75};
\end{tikzpicture}

Some common examples of exchange-correlation functionals include:
\begin{enumerate}
\item von Barth and Hedin
\item Gunnarsson and Lundqvist
\item Vosko, Wilk, and Nusair (VWN)
\end{enumerate}
Another category invokes the generalized gradient approximation (GGA). These exchange-correlation functionals go beyond LDA and involves a dependence on $\nabla n(\vec{r})$
\begin{equation}
E_{\trm{xc}}[n(\vec{r})]=\int\varepsilon_{xc}[n(\vec{r})]n(\vec{r})\dd{\vec{r}}+\int g[\nabla n(\vec{r})]\dd{\vec{r}}
\end{equation}
where $g[\nabla n(\vec{r})]$ is some functional acting on $\nabla n(\vec{r})$. Some examples include:
\begin{enumerate}
\item Becke, Lee, Yang, Parr (BLYP), which uses the Becke 88 exchange which tries to approximate the Hartree-Fock exchange by adding corrections to LDA exchange and LYP correlation term (which tries to reproduce the correlation of the helium atom)
\item Perdew, Burke, Ernzerhot (PBE)
\end{enumerate}
There are also hybrid methods, combining DFT with Hartree-Fock. Some examples include:
\begin{enumerate}
\item B3LYP, whose exchange term combines the Hartree-Fock exchange with the LDA exchange and Becke correction and whose correlation term combines the LYP correlation with the VWN correlation
\end{enumerate}
When comparing computational time for different methods, in general
\[
\trm{BLYP}<\trm{HF}<\trm{B3LYP}<\trm{CI}
\]
In comparison, the accuracy in general
\[
\trm{HF}<\trm{BLYP}<\trm{B3LYP}<\trm{CI}
\]
Note in the context of modeling systems, the choice of exchange-correlation functional will depend highly on the system as well as the property of interest.

\subsection{Connection to Thomas-Fermi-Dirac Model}
The Thomas-Fermi model assumes uniformly distributed electrons in the phase space and that the effective potential comes due to the nuclear charge and the electron distribution itself. To obtain the kinetic energy, one uses a 3D particle-in-a-box problem. This gives the density of states
\begin{equation}
g(\varepsilon)\sim\sqrt{\varepsilon}
\end{equation}
The electron density then is
\begin{equation}
n\sim \int \tikzmarknode{aa}{f_{\trm{FD}}}(\varepsilon)g(\varepsilon)\dd{\varepsilon}\sim\varepsilon_{F}^{\frac{3}{4}}\qq{(at 0 K)}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
	\draw[red,<-,shorten <=1mm] (aa.south) -- ++(0,-0.3) node[below]{Fermi-Dirac statistics};
\end{tikzpicture}

The kinetic energy density is
\begin{equation}
\rho_{\trm{KE}}\sim\int\varepsilon f_{\trm{FD}}(\varepsilon)g(\varepsilon)\dd{\varepsilon}\sim\varepsilon_{F}^{\frac{5}{2}}\sim n^{\frac{5}{3}}
\end{equation}
Thus, kinetic energy is
\begin{equation}
T_{\trm{TF}}[n(\vec{r})]=c_{F}\int n^{\frac{5}{3}}(\vec{r})\dd{\vec{r}}
\end{equation}
and the total energy is
\begin{equation}
E_{\trm{TF}}[n(\vec{r})]=c_{F}\int n^{\frac{5}{3}}(\vec{r})\dd{\vec{r}}+\int-\frac{Z}{r}n(\vec{r})\dd{\vec{r}}+\frac{1}{2}\int\frac{n(\vec{r})n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}}\dd{\vec{r}^{\prime}}
\end{equation}
One assumes that this is minimized for the ground state density, subject to the constraint
\begin{equation}
N=\int n(\vec{r})\dd{\vec{r}}
\end{equation}
Thus, the Lagrange problem after setting the variation to 0 is
\begin{equation}
\var{\qty{E_{\trm{TF}}[n(\vec{r})]-\mu_{\trm{TF}}\qty(\int n(\vec{r})\dd{\vec{r}}-N)}}=0
\end{equation}
One gets
\begin{equation}
\mu_{\trm{TF}}=\fdv{E_{\trm{TF}}[n(\vec{r})]}{n(\vec{r})}=\frac{5}{3}c_{F}n^{\frac{2}{3}}(\vec{r})+{\color{red}\underbrace{\color{black}\int\frac{n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}-\frac{Z}{r}}_{V_{\trm{eff}}(\vec{r})}}
\end{equation}
In the context of DFT
\begin{equation}
E_{0}[n(\vec{r})]=T[n(\vec{r})]+U_{\trm{ee}}[n(\vec{r})]+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}
\end{equation}
In the Thomas-Fermi model, $T[n(\vec{r})]$ is that of a uniform, non-interacting electron gas. This can be calculated using Hartree-Fock and the states of a particle-in-a-box problem with periodic boundary conditions, giving $c_{F}\int n^{\frac{5}{3}}(\vec{r})\dd{\vec{r}}$. Likewise, in this model, $U_{\trm{ee}}[n(\vec{r})]$ is simply the Coulomb term $J[n(\vec{r})]$.\\

Adding the Dirac exchange gives the Thomas-Fermi-Dirac model. Using the Hartree-Fock exchange formula with the same particle-in-a-box states as above gives
\begin{equation}
K[n(\vec{r})]=c_{\trm{x}}\int n^{\frac{4}{3}}(\vec{r})\dd{\vec{r}}
\end{equation}
Thus, the total energy is
\begin{equation}
E_{\trm{TFD}}[n(\vec{r})]=c_{F}\int n^{\frac{5}{3}}(\vec{r})\dd{\vec{r}}+\int v(\vec{r})n(\vec{r})\dd{\vec{r}}+J[n(\vec{r})]-c_{\trm{x}}\int n^{\frac{4}{3}}(\vec{r})\dd{\vec{r}}
\end{equation}
The Lagrange method gives
\begin{equation}
\mu_{\trm{TFD}}=\frac{5}{3}c_{F}n^{\frac{2}{3}}(\vec{r})-\frac{4}{3}c_{\trm{x}}n^{\frac{1}{3}}(\vec{r})+v_{\trm{eff}}(\vec{r})
\end{equation}
This can also be improved with the Thomas-Fermi-Dirac-Weizsacker model, which also adds a second-order gradient correction.\\

The problem currently is formulated in terms of electron density $n(\vec{r})$, but it can be connected to wavefunctions $\Psi_{i}(\vec{r})$ using the Hartree-Fock-Slater formalism
\begin{equation}
\qty[-\frac{1}{2}\nabla^{2}+v(\vec{r})+J[n(\vec{r})]-K[n(\vec{r})]]\Psi_{i}(\vec{r})=\varepsilon_{i}\Psi_{i}(\vec{r})
\end{equation}
which resembles the Kohn-Sham equations.

\subsection{Bloch's Theorem and Band Structures}
Bloch's theorem states that wavefunctions in a system with periodicity can be written as
\begin{equation}
\Psi_{nk}(\vec{r})=\mathcal{U}_{nk}(\vec{r})e^{i\vec{k}\cdot\vec{r}}
\end{equation}
where $\mathcal{U}_{nk}(\vec{r})$ has the same periodicity as that of a crystal, namely $\mathcal{U}_{nk}(\vec{r}+\vec{T})=\mathcal{U}_{nk}(\vec{r})$ with $\vec{T}$ describing the period. Thus
\begin{equation}
\Psi_{nk}(\vec{r}+\vec{T})=\mathcal{U}_{nk}(\vec{r})e^{i\vec{k}\cdot\vec{r}}e^{i\vec{k}\cdot\vec{T}}=\Psi_{nk}(\vec{r})e^{i\vec{k}\cdot\vec{T}}
\end{equation}
Let us cast $\mathcal{U}_{nk}(\vec{r})$ in the form of its Fourier series
\begin{equation}
\mathcal{U}_{nk}(\vec{r})=\sum_{\vec{G}}c_{nk,\vec{G}}e^{i\vec{G}\cdot\vec{r}}
\end{equation}
where $\vec{G}$ is called the \ul{reciprocal lattice vector}.\\

Recall the Schr\"{o}dinger equation for the Kohn-Sham method is
\begin{equation}
{\color{red}\underbrace{\color{black}\bigg[-\frac{1}{2}\nabla^{2}+v_{\trm{eff}}(\vec{r})\bigg]}_{\vb{H}_{\trm{eff}}}}\Psi_{nk}=\varepsilon_{nk}\Psi_{nk}
\end{equation}
Thus
\begin{equation}
\begin{aligned}
\vb{H}_{\trm{eff}}\qty(\sum_{\vec{G}}c_{nk,\vec{G}}e^{i(\vec{k}+\vec{G})\cdot\vec{r}})&=\varepsilon_{nk}\qty(\sum_{\vec{G}}c_{nk,\vec{G}}e^{i(\vec{k}+\vec{G})\cdot\vec{r}})\\
\implies \sum_{\vec{G}}\qty[\frac{1}{2}\abs{\vec{k}+\vec{G}}^{2}+v_{\trm{eff}}(\vec{r})]c_{nk,\vec{G}}e^{i(\vec{k}+\vec{G})\cdot\vec{r}}&=\varepsilon_{nk}\qty(\sum_{\vec{G}}c_{nk,\vec{G}}e^{i(\vec{k}+\vec{G})\cdot\vec{r}})
\end{aligned}
\end{equation}
Multiplying both sides by $e^{-i(\vec{k}+\vec{G}^{\prime})\cdot\vec{r}}$ and integrate over the space of $\vec{r}$
\begin{equation}
\begin{aligned}
\sum_{\vec{G}}\int\bigg[\frac{1}{2}\abs{\vec{k}+\vec{G}}^{2}+v_{\trm{eff}}(\vec{r})\bigg]e^{i(\vec{G}-\vec{G}^{\prime})\cdot\vec{r}}\dd{\vec{r}}c_{nk,\vec{G}}&=\varepsilon_{nk}\bigg[\sum_{\vec{G}}\int c_{nk,\vec{G}}e^{i(\vec{G}-\vec{G}^{\prime})\cdot\vec{r}}\bigg]\\
\implies\sum_{\vec{G}}\bigg[\frac{1}{2}\abs{\vec{k}+\vec{G}}^{2}\delta(\vec{G}-\vec{G}^{\prime})+{\color{red}\underbrace{\color{black}V_{\trm{eff}}(\vec{G}-\vec{G}^{\prime})}_{\mathclap{\trm{Fourier transform of $v_{\trm{eff}}$}}}}\bigg]c_{nk,\vec{G}}&=\varepsilon_{nk}c_{nk,\vec{G}}
\end{aligned}
\end{equation}
Assume a basis set (of plane waves) containing $M$ different vectors $\vec{G}$. Thus, the above equation can be written for all $\vec{G}^{\prime}$ that are part of this set. This gives the matrix equation
\begin{equation}
\vb{A}\vec{c}=\vb{\varepsilon}\vec{c}
\end{equation}
where the matrix elements $A_{ij}$ are given by
\begin{equation}
A_{ij}=\frac{1}{2}\abs{\vec{k}+\vec{G}_{i}}^{2}\delta(\vec{G}_{i}-\vec{G})+V_{\trm{eff}}(\vec{G}_{i}-\vec{G})
\end{equation}
and the vector elements are $c_{nk,\vec{G}_{i}}$.\\

Note that $k$ must be chosen for the coefficients $c_{nk,\vec{G}}$. This becomes a choice of \ul{$k$-point sampling}. One choice is the Monkhorst-Pack scheme which uses uniform sampling. One can also implement a cut-off energy
\begin{equation}
\frac{1}{2}\abs{\vec{k}+\vec{G}}^{2}<E_{\trm{cutoff}}
\end{equation}

\begin{center}
\begin{tikzpicture}
	\draw[<->,thick] (0,-1) -- (0,4) node[above] {$\varepsilon$};
	\draw[<->,thick] (-2.5,0) -- (2.5,0) node[right] {$k$};
	\draw[blue,<->,domain=-2:2,samples=200] plot (\x, {(\x)^2)});
	\draw[red,dashed] (0.4,0) -- (0.4,0.16) -- (0,0.16);
	\draw[red,dashed] (0.8,0) -- (0.8,0.64) -- (0,0.64);
	\draw[red,dashed] (1.2,0) -- (1.2,1.44) -- (0,1.44);
	\draw[red,dashed] (1.6,0) -- (1.6,2.56) -- (0,2.56);
	\draw[red,dashed] (2,0) -- (2,4) -- (0,4);
\end{tikzpicture}
\end{center}

\subsection{Finite Temperature DFT}
At finite temperature, entropy can no longer be ignored. One now has to look at the Helmholtz free energy.\\

The grand canonical potential is defined as
\begin{equation}
\Omega[n(\vec{r})]=T[n(\vec{r})]+U_{\trm{ee}}[n(\vec{r})]-\Theta S[n(\vec{r})]+\int\qty(v(\vec{r})-\mu)n(\vec{r})\dd{\vec{r}}
\end{equation}
where $\Theta$ is the temperature, $S$ is the entropy, and $\mu$ is the chemical potential.\\

The Helmholtz free energy is
\begin{equation}
A[n(\vec{r})]=T[n(\vec{r})]-\Theta S[n(\vec{r})]
\end{equation}
Let us define a reference system similar as before.
\begin{equation}
A_{\trm{ref}}[n(\vec{r})]=T_{\trm{ref}}[n(\vec{r})]-\Theta S_{\trm{ref}}[n(\vec{r})]
\end{equation}
Thus
\begin{equation}
\Omega[n(\vec{r})]=A_{\trm{ref}}[n(\vec{r})]+J[n(\vec{r})]+\int\qty(v(\vec{r})-\mu)n(\vec{r})\dd{\vec{r}}+{\color{red}\underbrace{\color{black}F_{\trm{xc}}[n(\vec{r})]}_{\mathclap{\substack{\trm{exchange correlation}\\ \trm{functional}}}}}
\end{equation}
where
\begin{equation}
F_{\trm{xc}}[n(\vec{r})]=\qty(A[n(\vec{r})]-A_{\trm{ref}}[n(\vec{r})])+\qty(U_{\trm{ee}}[n(\vec{r})]-J[n(\vec{r})])
\end{equation}
Minimizing $\Omega[n(\vec{r})]$ gives the finite temperature Kohn-Sham equations. One gets
\begin{equation}
\fdv{A_{\trm{ref}}[n(\vec{r})]}{n(\vec{r})}+\int\frac{n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+\qty(v(\vec{r})-\mu)+\fdv{F_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}=0
\end{equation}
Thus
\begin{equation}
\qty(-\frac{1}{2}\nabla^{2}+v_{\trm{eff}}(\vec{r}))\Psi_{i}(\vec{r})=\varepsilon_{i}\Psi_{i}(\vec{r})
\end{equation}
where
\begin{equation}
v_{\trm{eff}}(\vec{r})=v(\vec{r})+\int\frac{n(\vec{r}^{\prime})}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+\fdv{F_{\trm{xc}}[n(\vec{r})]}{n(\vec{r})}
\end{equation}
and
\begin{equation}
n(\vec{r})=\sum_{i=1}^{\infty}f_{i}\Psi_{i}^{*}(\vec{r})\Psi_{i}(\vec{r})
\end{equation}
with $f_{i}$ being the Fermi-Dirac distribution given by
\begin{equation}
f_{i}=\frac{1}{1+e^{\frac{\varepsilon_{i}-\mu}{k_{B}T}}}
\end{equation}
The exchange-correlation functional can be dealt with much in a similar manner as was done at zero temperature. For example, one can do LDA, where one assumes the potential at each point in space equals the free energy of a uniform electron gas at temperature $\Theta$ whose density is equal to the density of the actual system at that point.

\subsection{Time-Dependent DFT}
Recall in time-independent DFT, the electron density $n(\vec{r})$ uniquely determines the external potential $v(\vec{r})$ to an additive constant. A similar relation holds in the time-dependent case and was shown in 1984 by Runge and Gross, but the additive constant is now time-dependent, though it remains spatially constant. Note that this assume $v(\vec{r},t)$ can be Taylor expanded about some initial time and both $v(\vec{r},t)$ and $n(\vec{r},t)$ vanish at the boundary of the system.\\

Functionals now depend on $[n,\Psi_{0},\phi_{0}]$, where $\Psi_{0}$ is the initial many-body state at time $t_{0}$ (starting point) and $\phi_{0}$ is the initial Kohn-Sham state.\\

Moreover
\begin{equation}
v_{\trm{eff}}(\vec{r},t)=v(\vec{r},t)+\int\frac{n(\vec{r}^{\prime},t)}{\abs{\vec{r}-\vec{r}^{\prime}}}\dd{\vec{r}^{\prime}}+v_{\trm{xc}}[n,\Psi_{0},\phi_{0}](\vec{r},t)
\end{equation}
The effective Hamiltonian equation is
\begin{equation}
\qty(-\frac{1}{2}\nabla^{2}+v_{\trm{eff}}(\vec{r},t))\Psi_{j}(\vec{r},t)=i\pdv{t}\Psi_{j}(\vec{r},t)
\end{equation}
with
\begin{equation}
\Psi_{j}(\vec{r},t)=\Psi_{\trm{amp},j}(\vec{r},t)\exp\qty(i\Psi_{\trm{phase},j}(\vec{r},t))
\end{equation}
and
\begin{equation}
n(\vec{r},t)=\sum_{j=1}^{N}\Psi_{j}^{*}(\vec{r},t)\Psi_{j}(\vec{r},t)
\end{equation}
$v_{\trm{xc}}[n,\Psi_{0},\phi_{0}](\vec{r},t)$ can be treated with an adiabatic approximation, where the functional uses LDA given the electron density at that given time.

\newpage
\section{Semi-empirical Electronic Structure Modeling}
At the start of the course, topics focused on ab-initio (first-principles) methods, such as Hartree-Fock, which did not bring any parameters from empirical observations, experiments, or other methods. This was followed by post Hartree-Fock methods, which include configuration interaction and perturbation theory. Afterwards, we considered density functional theory.\\

Let us now consider semi-empirical methods. These will include linear combinations of atomic orbitals, tight-binding theory, H\"{u}ckel theory, PPP methods, etc.\\

We are trying to solve problems of the form $\vb{FC}=\vb{SC\varepsilon}$. In practice, semi-empirical methods approximate $\vb{F}$ and $\vb{S}$ in order to reduce the computations required to solve this eigenvalue problem.\\

\subsection{H\"{u}ckel Theory}
Consider H\"{u}ckel $\pi$-orbital theory. In this theory, the core electrons and their effects are lumped in together with the nuclei. Slater type orbitals are also used as basis functions to describe $\pi$-orbitals. Furthermore, the basis functions are assumed to be orthogonal (i.e. $\vb{S}=\id$).\\

Let us now attempt to determine the matrix elements of the effective Hamiltonian. Note that the same atom, put in different molecular systems, would lead to different Hamiltonian matrix elements. This can be illustrated in the system of pyridine and pyrrole.

\begin{center}
\begin{tikzpicture}
	\draw (0,0) coordinate (A) node[above right,yshift=0.1cm] {\small C} -- ++(0:2) coordinate (B) node[above left,yshift=0.1cm] {\small N};
	\draw[double distance=3pt] (B) -- ++(60:2) coordinate (C) node[left,xshift=-0.1cm] {\small C};
	\draw (C) -- ++(120:2) coordinate (D) node[below left,yshift=-0.1cm] {\small C};
	\draw[double distance=3pt] (D) -- ++(180:2) coordinate (E) node[below right,yshift=-0.1cm] {\small C};
	\draw (E) -- ++(240:2) coordinate (F) node[right,xshift=0.1cm] {\small C};
	\draw[double distance=3pt] (F) -- (A);
	\draw[white,fill=black,line width=2pt] (A) circle (3pt);
	\draw[white,fill=black,line width=2pt] (B) circle (3pt);
	\draw[white,fill=black,line width=2pt] (C) circle (3pt);
	\draw[white,fill=black,line width=2pt] (D) circle (3pt);
	\draw[white,fill=black,line width=2pt] (E) circle (3pt);
	\draw[white,fill=black,line width=2pt] (F) circle (3pt);
\end{tikzpicture}
\end{center}


\end{document}
